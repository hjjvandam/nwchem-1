% $Id: prog.tex,v 1.6 1997-05-04 18:54:22 d3g681 Exp $
\documentstyle[fullpage,12pt]{article}
\setlength{\parskip}{6pt}

\newcommand{\TRUE}{\verb+.true.+}
\newcommand{\FALSE}{\verb+.false.+}

\begin{document}

\title{\bf\Large NWCHEM Programmer's Guide, Beta Release 2.0}
\author{High Performance Computational Chemistry Group}
\date{\today}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{\center DISCLAIMER}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This material was prepared as an account of work sponsored by an agency of the
United States Government.  Neither the United States Government nor the United
States Department of Energy, nor Battelle, nor any of their employees, MAKES
ANY WARRANTY, EXPRESS OR IMPLIED, OR ASSUMES ANY LEGAL LIABILITY OR
RESPONSIBILITY FOR THE ACCURACY, COMPLETENESS, OR USEFULNESS OF ANY
INFORMATION, APPARATUS, PRODUCT, SOFTWARE, OR PROCESS DISCLOSED, OR REPRESENTS
THAT ITS USE WOULD NOT INFRINGE PRIVATELY OWNED RIGHTS.


\begin{center}
{\bf LIMITED USE}
\end{center}

This software (including any documentation) is being made available to
you for your internal use only, solely for use in performance of work
directly for the U.S. Federal Government or work under contracts with
the U.S. Department of Energy or other U.S. Federal Government
agencies.  This software is a version which has not yet been evaluated
and cleared for commercialization.  Adherence to this notice may be
necessary for the author, Battelle Memorial Institute, to successfully
assert copyright in and commercialize this software.  This software is
not intended for duplication or distribution to third parties without
the permission of the Manager of Software Products at Pacific
Northwest National Laboratory, Richland, Washington, 99352.

\begin{center}
{\bf ACKNOWLEDGMENT}
\end{center}

This software and its documentation were produced with Government support under
Contract Number DE-AC06-76RLO-1830 awarded by the United States Department of
Energy.  The Government retains a paid-up non-exclusive, irrevocable worldwide
license to reproduce, prepare derivative works, perform publicly and display
publicly by or for the Government, including the right to distribute to other
Government contractors.


\clearpage

\begin{center}
{\bf AUTHOR DISCLAIMER}
\end{center}

This software contains proprietary information of the authors, Pacific
Northwest National Laboratory (PNNL), and the US Department of Energy (USDOE).
The information herein shall not be disclosed to others, and shall not
be reproduced whole or in part, without written permission from PNNL or
USDOE.  The information contained in this document is provided ``AS
IS'' without guarantee of accuracy.  Use of this software is
prohibited without {\bf written} permission from PNNL or USDOE.  The
authors, PNNL, and USDOE make no representations or warranties
whatsoever with respect to this software, including the implied
warranty of merchant-ability or fitness for a particular purpose.  The
user assumes all risks, including consequential loss or damage, in
respect to the use of the software.  In addition, PNNL and the authors
shall not be obligated to correct or maintain the program, or notify
the user community of modifications or updates that will be made over
the course of time.


\clearpage

\tableofcontents

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{An introduction to CVS}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Author: David Bernholdt

CVS, which stands for {\it Concurrent Version System} is a revision
control package designed to facilitate multiple developers working on
the same software package.  It is implemented as a layer on top of RCS
and provides a number of useful features which RCS alone does not.

To my mind, the two most important of these features are 
\begin{itemize}
\item The RCS check-in/checkout locking mechanism introduces a coupling
between developers at the level of the source file they want to work
on, despite the practical reality that even within a given source
file, changes are usually orthogonal.  CVS does not require exclusive
locks on sources during the development process and provides for
merging of orthogonal changes to the same source file (overlapping
changes are flagged for manual resolution during the merger process).

\item RCS works on a per-file basis, and unless great care is taken,
changes can be forgotten or lost.  Most CVS commands work recursively
on the entire contents of a directory tree (with command line switches
to limit operation to the local directory), making it easy to identify
all files which have changed, check them in, etc.
\end{itemize}
This note
is meant to outline the model which CVS uses for the software
development process and to connect that model with the basic commands
of the program itself.  Hopefully once the basics are under control,
the more sophisticated aspects of the program can be understood from
the man pages.

\subsection{The CVS Model}

CVS divorces the directory tree in which development takes place from
the directory tree in which the master copy of the sources are kept.
The latter directory tree is referred to as the {\em repository}, and
it has exactly the same structure as the working directory tree.  Where
the working tree would have source files, the repository has the RCS
files for the sources (i.e., {\tt source.f,v}).

Each user who wants to work on a program checks it out of the
repository into their own directories.  The working copy is (by
default) created giving the user read and write permission on all of
the files, and can be used directly.  When a developer has completed
(and tested) a set of changes, they can check the revised sources into
the repository.  The other developers are uneffected by the change to
the repository until they either update their copy of the source or
check out new copy.  Anyone checking out a new working copy will
always get the latest version present in the repository.

Developers can ``poll'' the repository for changes and update {\em
  their working copy} with the changes between their last checkout or
update and the current version.  The repository is entirely unaffected
by an update; only the developer's private working copy is changed.
Most often, even within the same source file, changes made by
independent developers will not conflict.  As long as they don't CVS
handles the merger automatically.  If they do conflict, it is up to
the developer to fix them.  It is then the individual developer's
responsibility to insure that whatever they have been working on
meshes properly with the changes others have put into the repository.
Note that although CVS reduces the coupling between developers
actually wanting to edit a particular source, it does not eliminate
the need for communication, so that changes which functionally
conflict (regardless of whether the source changes conflict) can be
avoided.

\subsection{The CVS Program}

CVS is implemented as a single program named {\tt cvs} which has many
subcommands.  It is worth noting both the cvs command itself and the
subcommand accept a variety of command line switched which are
distinguished by their position: {\tt cvs [cvs\_options] subcommand
[subcommand\_options] [arguments]}.  The man page lists the
applicable options for the cvs command itself and for each subcommand.

CVS must be told of the location of the repository.  This can be done
with the cvs\_option (i.e. {\tt -d /msrc/proj/mss}) or by setting
the environment variable {\it CVSROOT}.  Although the CVS man pages
implicitly use a single repository for all projects under CVS control,
this is not strictly necessary.  At Florida, I had a private CVS
repository, one for my research group, and one for software I added to
the system, which I accessed by changing the definition of {\tt CVSROOT}.

CVS thinks in terms of source {\em modules}.  Basically this is some
collection of source which it is sensible to work on.  The module can
simply be the name of a directory within the repository (i.e. {\tt
nwchem} or {\tt nwchem/src}) or it defined as a collection of selected
bits and pieces of the directories within the repository.  For
instance, we might eventually find it useful to avoid checking out the
Argos sources or the distributed data package in some circumstances,
so modules could be defined to give these results.

To check out a working copy of a repository, go to the place in your
directory tree where you want the copy to live and give the command
{\tt cvs co nwchem} (or whatever module you want; nwchem is the one
of interest to most of us).

As you are working, you may want to compare your sources with those
you checked out.  This can be done with the {\tt cvs diff} command,
which accepts the same arguments as rcsdiff.  You can specify
particular files, or let it do the entire directory tree recursively.
{\tt cvs log} is the equivalent of the RCS rlog command and operates
similarly to {\tt cvs diff}.

The {\tt cvs update} command is used to merge changes to the
repository into your working copy.  Recurses through the directory
tree and reports files you have modified with an ``M'', and files
which have changed in the repository with a ``U''.  Files which did
not come from the repository are marked with a ``?''.  There are a
number of other codes for other circumstances, which are detailed in
the man pages. If you just want to check what has changed without
merging from the repository, use {\tt cvs -n update}.

To inform CVS that you are intentionally removing a file under its
control, first remove it with the Unix {\tt rm} command, then use {\tt
cvs rm} to notify CVS\@.  When you check-in this (nonexistent) file the
next time, it will be moved to a special place in the repository where
it can be recovered if old versions which require it are check out,
but where it will not appear in future working copies.

To give CVS control over files, you {\tt cvs add} them.  Like {\tt cvs
rm}, the actual addition takes place at the next check-in.  As with
the first RCS check-in of a file, {\tt cvs add} will prompt you for a
description of the file (not a log message -- that happens at
check-in).  New directories must also be added with {\tt cvs add}, but no
description is requested.

To check-in your changes use {\tt cvs ci}.  As with {\tt cvs diff},
it will accept particular file names or recurse through the directory
tree looking for files you have modified.  You are asked to write a
log message for the files you check-in.  If you give specific filenames
to check-in, the log message applies to all of them.  If you let it
figure out which files to check-in, you are asked for a log message for
all of the modified files in a given directory.  The {\tt EDITOR}
environment variable is used to decide which editor to bring up to
enter the log message.

CVS automatically tracks which versions if the sources your working
copy is based on, so it determines whether your changes would be
checked in on a branch or the main trunk, etc.

If you want to get rid of a working directory, the best thing to do is
{\tt cvs release -d nwchem} in the directory above it.  This command
checks your files to make sure you are not accidentally abandoning any
changes which haven't been checked in, then delete the entire
directory tree (leaving off the {\tt -d} just does the check without
deleting anything).

There is a lot more that can be done with CVS, but these basics should
get you started.  I {\em strongly} recommend you take the time to read
through the CVS man pages to get a better feel for everything that can
be done.  If you are unsure of what a command will do, try it first
with a {\tt -n} option on cvs itself.  This is like ``make -n'', which
reports what it would do if invoked without the {\tt -n}.

\subsection{Summary of CVS commands}

For a really brief reference, look below.  A bit more detail is in
\verb+nwchem/doc/cvshelp.man+ and the full gore is available from
\verb+man cvs+.

\begin{description}
\item{\verb+setenv CVSROOT /msrc/proj/mss+} --- in the \verb+csh+ this
  defines the path to the CVS repository.  Put this in your
  \verb+.cshrc+ or \verb+.mycshrc+.
 
\item{\verb+cvs co nwchem+} --- checks out the entire source for NWChem into
  the directory \verb+nwchem+.  The repository is unaffected.
  
\item{\verb+cvs -n update+} --- compares the contents of the current
  directory and all subdirectories against the repository and flags
  files according to their status:
  \begin{description}
  \item{\verb+?+} --- the file is not maintained by CVS.
  \item{\verb+M+} --- your checked-out version differs from the original
    (i.e., you edited it).
  \item{\verb+U+} --- your checked-out version is out-of-date and
    needs updating.
  \item{\verb+C+} --- potential conflict. You have changed this file
    and the source in the repository has also changed.
  \item{File not listed} --- your source is the same as that in the repository.
  \end{description}
  Neither the repository nor your source are changed.

\item{\verb+cvs update+} --- updates the contents of the current
  directory and all subdirectories with the latest versions of the
  source, again flagging files according to their status. {\em You are
    responsible for correcting files that CVS flags as containing
    conflicts between edits you and others have made.} However, CVS
  handles all other merging.  New files will also be added to your
  source, however, to get new directories you must append the
  \verb+-d+ flag.  Your source is changed; the repository is
  unaffected.

\item{\verb+cvs diff filename+} --- generates differences between the
  file and the version of the file you checked out (i.e., it indicates
  edits you made).  If you want to compare against the most recent
  version in the repository use \verb+cvs diff -r head filename+.
  Neither the repository nor your source are changed.

\item{\verb+cvs add filename+} --- adds a new file to the repository.
  The new file is not actually added until you execute \verb+cvs
  commit+.  Changes CVS internal information in your source tree but
  does not affect the repository.

\item{\verb+cvs rm filename+} --- to delete a file from the repository
  delete it from your source with the standard UNIX \verb+rm+ command
  then tell CVS to delete it with this command.  The file
  is not actually removed until you execute \verb+cvs commit+.  Changes CVS
  internal information in your source tree but does not affect the
  repository.
  
\item{\verb+cvs commit+} --- this is the only command that affects the
  repository.  Before committing changes and updating the repository
  with changes in a list of files or the current directory tree you
  must
  \begin{itemize}
  \item ensure that all of your sources are up-to-date with respect to
    the repository by using \verb+cvs update+,
  \item resolve all conflicts resulting from the update, and
  \item ensure that the updated code functions correctly.
  \end{itemize}
  Commit will verify that all source is up-to-date before proceeding.
  Then it will prompt (using an editor) for log messages describing
  the changes made.  Be as detailed as possible.
\end{description}

\subsection{Trouble shooting}

{\em Under no circumstances edit, move, delete or otherwise mess with
  files in the repository (\verb+/msrc/proj/mss/nwchem+), unless you really
  know what you are doing.  CVS breaks easily.  Consult with Dave,
  Robert, Rick, Edo or Adrian if you think that there are problems.}

If you checked out a specific version then CVS usually remembers this
(the version information is termed sticky) and this can get really
confusing since \verb+cvs update+, etc., will not refer to the latest (or
head) version.  Changes that you know have been made will magically
disappear.  This may be what you want.  However, if you want to get
back to the latest version use the \verb+-A+ flag (e.g., \verb+cvs
update -A+).

If CVS is interrupted, or there is an AFS to NFS translator problem,
it may occasionally leave lock files in the CVS repository, causing
subsequent commands to wait forever printing messages indicating it is
waiting for someone to relinquish access to a specific directory.
Fixing this requires deleting files from the repository.  Ask Dave,
Robert, Rick, Edo or Adrian for help.

It is unclear if this next problem still exists within EMSL but it may
arise elsewhere.  Because of a problem with the AFS version of the ci
command, which is used by CVS, you must have {\tt
  /usr/local/lib/rcs/diff} on your system.  The easiest way to do this
is to create the {\tt /usr/local/lib/rcs directory} and put in it a
symbolic link to the GNU diff program, {\tt /msrc/bin/diff}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Coding Style}
\label{sec:coding-style}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In a project this large, it is necessary to impose some standards on
the coding style employed by developers.  The primary goal of these
standards is not to constrain developers, but to enhance both the
quality of the final product and its functionality. 

Code quality is somewhat subjective, but clearly embraces the ideas of
\begin{itemize}
\item correctness, 
\item maintainability, 
\item efficiency, 
\item readability, 
\item re-usability, 
\item modularity, 
\item ease of integration with other packages,
\item speed of development, 
\item density of bugs, 
\item ease of debugging, 
\item detection of errors at run time,
\item exposure of available functionality,
\item ease-of-use of the API,
\item etc..
\end{itemize}
Compromise is clearly necessary. We are interested in
high-performance, so some key kernels may sacrifice readability (but
perhaps not modularity) for efficiency, but most code (i.e., 99.9\%)
is not an inner loop in need of such optimization, as long as the
overall structure is correct.

The single most important thing you can do to achieve quality code has
little to do with programming style --- {\em it is design} --- putting
in the necessary thought and effort before even a single line of code
is written.  Do not assume that if you comply with all of the
suggestions below that you are necessarily writing quality code or
that any routine cannot be further improved.

\subsection{No globally defined common blocks}

Use of global variables (e.g., common blocks) is generally a bad idea.
Such variables break modularity, form hidden dependencies and make
code hard to reuse and maintain.  {\em Do not use common blocks to
  pass data between routines}.

However, common blocks are very useful in supporting a modular
programming style which encourages code reuse and improves
maintainability.  To this end common blocks can be used to hide data
behind a subroutine interface so that access to the common is limited
to a few tightly integrated routines.  The benefits of using common
blocks (smaller argument lists, static data allocation, contiguous
memory layout) can thus, with care, be realized without any problems.
Examples of this include the basis, geometry, RTDB, integral,
symmetry, global array, message passing, SCF, optimizer, input, and
MP2 libraries.

\subsection{Naming of routines and common blocks}

To avoid name clashes and for easy identification, prefix all
subroutine, function and common block names with the name of the
module they are associated with.  For instance,
\begin{itemize}
\item {\tt rtdb\_\ldots} --- run-time database
\item {\tt ma\_\ldots} --- memory allocator
\item {\tt ga\_\ldots} --- global array
\item {\tt scf\_\ldots} --- SCF
\item {\tt stpr\_\ldots} --- Stepper (geometry optimization)
\end{itemize}

We have already had name clashes which have wasted several days of
man-time to resolve.

\subsection{Inclusion of common block definitions}

All common block definitions (including typing of variables in the
common) are to be made once only in a single file (a {\tt.fh} file)
which is to be included in other source using the C preprocessor.  The
include file should document the meaning of all variables.  

This is so that variables in a common block are consistently named and
so that dependencies of routines on common blocks are easily generated
and maintained.


\subsection{No implicitly typed variables}

Insert {\tt implicit none} at the top of every routine.  No other
implicit statements are permitted and all variables must be explicitly
declared.  {\em This rule should be strongly enforced in new code.} It
\begin{itemize}
\item helps the compiler help you find typos and other errors,
\item makes the code more readable and more maintainable,
\item provides a natural point to document arguments and local
  variables, and
\item makes use of silly variable names like {\tt iii, ii1} both
  obvious and even more embarrassing when others catch you doing it.
\end{itemize}

When integrating existing code this rule may make more work than it is
worth, however several bugs in existing code have been found in this
fashion (ask Martyn).

\subsection{Use {\tt double precision} rather than {\tt real*8}}

{\tt REAL*8} is not standard Fortran.  {\tt DOUBLE PRECISION} is the
standard, it is usually what you want, it is more portable and
standardization of declarations enables us to perform more readily 
necessary code transformations.

\subsection{Naming of variables holding handles/pointers obtained from
  MA/GA}

So that these critical variables are immediately recognizable the
following conventions are recommended, though commenting of
variables at the point of declaration suffices if you don't want to
follow these:
\begin{itemize}
\item Handles obtained from MA should be prefaced with {\tt l\_}.
\item Pointers (into {\tt dbl\_mb()}, etc.) obtained from MA should be
  prefaced with {\tt k\_}.
\item Handles obtained from GA should be prefaced with {\tt g\_}.
\end{itemize}

\subsection{C macro definitions should be in upper case}

NWChem uses the ANSI C preprocessor to handle machine dependencies and
other conditional compilation requirements.  By forcing all C macros
to be upper case the code is made more readable and we also avoid
potential accidental munging of Fortran source.  This practice is
consistent with conventional use of the preprocessor in C programs.

\subsection{Fortran source should be in lower or mixed case}

This convention is complementary to the above C macro convention.
If there are no fully upper-case Fortran tokens then there can
be no accidental conflict with the C preprocessor.

\subsection{Syntax for including files using the C preprocessor}

The two different forms
\begin{itemize}
\item \verb+#include "filename"+, and
\item \verb+#include <filename>+,
\end{itemize}
mean different things.  Quoting from Kernighan and Ritchie:
\begin{quotation}
 If the {\em} filename is quoted, searching for the file typically
 begins where the source program was found; if it is not found there,
 or if the name is enclosed in \verb+<+ and \verb+>+, searching follows
 an implementation-defined rule to find the file.
\end{quotation}
For this reason, and by common convention, only system defined include
files are included using angle brackets and include files defined
within an application are included using quotes.  The
automatic generation of dependencies of source files upon include
files with NWChem {\em relies} upon this convention.

\subsection{Convention for naming include files}

\begin{itemize}
\item Use \verb+.fh+ for files that can be included only by Fortran
\item Use \verb+.h+ for files that can be included by C, or
  for files that are included by both C and Fortran.
\end{itemize}

\subsection{Parameterize message IDs}

Why use tags/IDs/types on messages?  If all messages with the program
have distinct types and the message-passing software forces the types
of messages to match between sender and receiver, then either a
runtime error will be detected or you have a proof that the messages
are being sent and received correctly.  This is especially important
to NWChem since we use many third party linear algebra libraries that
do a lot of message passing.

Modules which do any messaging should reserve a section of the message
ID space for their use (e.g., GA or PEIGS).  Most modules, however, do
only a small amount of messaging.  For these, the include file {\tt
  msgids.fh} should be used to reserve individual message IDs.  This
file defines Fortran parameters for message IDs used in most NWChem
modules referenced to a single base value.  No NWChem routine should
contain a hardwired message ID.

\subsection{Parameterize Fortran unit numbers}

All references to Fortran I/O units should be done with parameters or
variables instead of hardwired constants.  For the ``standard I/O''
units, corresponding to the C stdin, stdout, and stderr, you should
include the file {\em stdio.fh} and use the variables \verb+luin+,
\verb+luout+, and \verb+luerr+ instead of 5, 6, and 0.

We use very few other files, so there is nothing organized for
non-stdio units at the moment.  Parameterization helps insure that
these can be changed simply if needed, and facilitates moving to a
more general mechanism later.

\subsection{Comments}

The more the merrier.  At least
\begin{itemize}
\item include terse comments at the top of each subroutine to describe
  (accurately!) its function,
\item document dependencies/effects on state that are not passed
  directly through its argument list (e.g., files, the database, common
  blocks)
\item describe arguments including the flow of information (i.e.,
  label arguments as in/out/in-out)
\item document local variables whose function is not apparent
  from their names, or whose algorithmic role is opaque or obscure.
\end{itemize}

In some circumstances, comments at the top of a routine can be quite
lengthy since this is a {\tt very} good place to store details of the
algorithm.  However, too many comments in the body of the source can
impair readability.

If an interface is finalized and is to be exported for use by others,
it should be documented here in {\tt prog.tex} --- nearly all of the
documentation in this file was generated by pasting in existing
comments in the source.  {\em Automatic generation of documentation
  from code comments is being designed.}

Not much more than the following is required.  E.g., 
\begin{verbatim}
  logical function bas_numbf(basis,nbf)
  implicit none
  integer basis   ! [input] basis set handle         
  integer nbf     ! [output] number of basis functions
*
*  nbf returns the total number of functions.
*  Returns true on success, false if the handle is invalid
*  
\end{verbatim}

Or, e.g.,
\begin{verbatim}
      subroutine sym_symmetrize(geom, basis, odensity, g_a)
C$Id: prog.tex,v 1.6 1997-05-04 18:54:22 d3g681 Exp $
      implicit none
      integer geom, basis  ! [input] Handles
      integer g_a          ! [input] Handle to input/output GA
      logical odensity     ! [input] True if matrix is a density
c
c     Symmetrize a skeleton matrix (in a global array) in the
c     given basis set.
c
c     A <- (1/2h) * sum(R) [RT * (A + AT) * R]
c
c     where h = the order of the group and R = operators of the
c     group (including the identity)
c
c     Note that density matrices transform according to slightly
c     different rules to Hamiltonian matrices if components
c     of a shell (e.g., Cartesian d's) are not orthonormal.
c     (see Dupuis and King, IJQC 11, 613-625, 1977)
\end{verbatim}


\subsection{Version information}

Each source file should include a comment line that contains the CVS
revision and date information.  This is accomplished by including a
comment line containing the string \verb+$+\verb+Id+\verb+$+.  CVS
substitutes the correct version information each time the file is
checked out or updated.  These lines are processed from the source and can be
output at runtime to aid in bug-tracking.

\subsection{Standard print control}

All modules should understand the \verb+PRINT+ directive and
accept at least the following keywords for this
\begin{itemize}
\item \verb+none+ --- no output whatsoever except for error messages
\item \verb+low+ --- minimal output, e.g., title, critical parameters
and a final energy
\item \verb+medium+ = \verb+default+ --- usual output
\item \verb+high+ --- extra verbose output
\item \verb+debug+ --- anything useful for diagnosing problems
\end{itemize}

Ideally all applications should control most printing via the print
control routines described below (section \ref{sec:print}).  A uniform
look and feel is important.


\subsection{Standard interface for top-level modules}

In order to allow for automatic configuration of various modules in
a compilation of NWChem (to control the size of the executable
in memory-critical situations), all top-level modules must have a
standard interface.  Currently it looks like
\begin{verbatim}
  logical function MODULE(rtdb)
\end{verbatim}
where \verb+rtdb+ is the handle for the run-time database.  The
function should return \TRUE\ or \FALSE\ on success or failure
respectively.

The only sources of information for a module is the database, or files
whose name can be inferred from data in the database or from defaults.
Futhermore the naming of database entries is standardized:
\begin{itemize}
\item The string with which database entries are prefixed must be
  lowercase and match the module name used in the input.  E.g., input
  for the SCF module appears in the \verb+scf;...;end+ block and the
  prefix used in the databse is \verb+scf+.  This is so that the user
  can delete all state information using the \verb+UNSET+ directive.
\item Common quantities (such as energy, gradient, \ldots) should be
  stored using that name.  E.g., \verb+scf:energy+.
\end{itemize}


\subsection{Error handling}

All fatal errors should result in a call to \verb+errquit()+ (section
\ref{errquit}), which prints out the string and status value to both
standard error and standard output and attempts to kill all parallel
processes and to tidy any allocated system resources (e.g., system V
shared memory).

\subsection{Bit operations --- {\tt bitops.fh}}

{\em Dave is looking into additions to the F77 standard to see what 
is stated there --- we will adopt whatever is the standard and change
existing source accordingly.}

We have standardized upon the following bitwise operations (see Table
\ref{tabbit} for definitions) since they are readily generated using
in-line functions from most other definitions
\begin{itemize}
\item \verb+ior(i,j)+ --- inclusive OR
\item \verb+ieor(i,j)+ --- exlusive OR
\item \verb+iand(i,j)+ --- AND
\item \verb+not(i)+ --- NOT or one's complement
\item \verb+rshift(i,nbits)+ --- right shift with zero fill
\item \verb+lshift(i,nbits)+ --- left shift with zero fill
\end{itemize}
\begin{table}[h]
\begin{center}

\begin{tabular}{c|c|c|c|c|c}
 ior   &   ieor   &    iand  &   not  & lshift   & rshift   \\ \hline
       &          &          &        &          &          \\
 110   &   110    &    110   &   10   & 10111011 & 10111011 \\
 100   &   100    &    100   &        & 2 bits   & 2 bits   \\ \hline
 110   &   010    &    100   &   01   & 11101100 & 00101110 
\end{tabular}
\vspace{0.2in}
\caption{\label{tabbit} Effect of the bit operations.  The shift examples
  use an eight bit word written with the most significant bit on the
  left.}


\end{center}
\end{table}

All operations operate on full integer words (32 or 64 bit as
necessary) and produce integer results.  The declarations and any
necessary statement functions are in \verb+bitops.fh+.  The presence
of data statements makes it impossible to have a single include file
make declarations and define statement functions.  To circumvent this
the declarations are in \verb+bitops_decls.fh+ and the statement
functions are in \verb+bitops_funcs.fh+.

\subsection{Blockdata statements and linking}

At least one machine (the CRAY-T3D) discards all symbols that are not
explicitly referenced, even if other symbols from the same \verb+.o+
file are used.  Thus, \verb+BLOCK DATA+ subprograms are not linked in.
One fix to this was to declare each \verb+BLOCK DATA+ subprogram as an
undefined external on the link command, but this makes the link
command depend on the list of modules being built.  An alternative
mechanism that works on the T3D is to reference each \verb+BLOCK DATA+
subprogram in an \verb+EXTERNAL+ statement within a \verb+SUBROUTINE+ or
\verb+FUNCTION+ that is guaranteed to be linked if any reference is to
be made to the \verb+COMMON+ block being initialized.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Makefiles and libraries}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In your environment, or on the make command line, you must specify two
variables
\begin{itemize}
\item {\tt NWCHEM\_TARGET} --- the name of the machine to build for.
\item {\tt NWCHEM\_TOP} --- the full path to the top level NWChem
  directory.
\end{itemize}
Look in the {\tt README} file in the top-level NWChem directory for
information about supported target platforms.  For instance, you might
insert the following in your \verb+.cshrc+ file on a SUN with SunOS
4.1.3 
\begin{verbatim}
  setenv NWCHEM_TARGET SUN
  if (! $?NWCHEM_TOP) setenv NWCHEM_TOP $HOME/nwchem
\end{verbatim}
%$ ... to unscrew emacs latex hiliting
(the test to see if \verb+NWCHEM_TOP+ is already defined permits you
to build in an alternative directory without having to edit your
\verb+.cshrc+ file).  Given just this information the structure of
NWChem makes it easy to write a makefile to build a library for a
module (.e.g, {\tt libddscf.a} for the SCF module) or to add routines
into a library shared between multiple modules (e.g., {\tt libutil.a}
which includes at least the util, geometry, basis, global, and ma
trees).

A minimal makefile looks like this
\begin{verbatim}
      LIBRARY = libminimal.a
          OBJ = a.o b.o c.o

include ../config/makefile.h
include ../config/makelib.h
\end{verbatim}

The above specifies that the object files are to be generated by
compiling available source (C or Fortran, without optimization) and
put into the library {\tt libminimal.a} (in the NWChem library
directory).  Nothing else is necessary.  If the library source is not
located in a subdirectory of the NWChem {\tt src} directory then the
path to the included files must be modified accordingly.

A slightly more complex makefile looks like this
\begin{verbatim}
      LIBRARY = libsimple.a
          OBJ = a.o b.o c.o
 OBJ_OPTIMIZE = d.o
    USES_BLAS = c.o
      HEADERS = simple.fh
  LIB_TARGETS = test

include ../config/makefile.h
include ../config/makelib.h

test: test.o $(LIBRARY_PATH)
      $(LINK.f) -o $@ $^

a.o b.o c.o test.o: simple.fh private.fh
\end{verbatim}

This makefile builds the library {\tt libsimple.a} from four object
files of which only one ({\tt d.o}) is optimized.  The source
associated with {\tt c.o} uses FORTRAN BLAS and will be automatically
converted on machines where 64 bit reals are single precision (e.g.,
requiring {\tt sgemm()} rather than {\tt dgemm()}).  The header file
{\tt simple.fh} is exported automatically into the NWChem include
directory ({\tt src/include}) where it may be included by other
modules which reference these routines.  Associated with the module is
the executable {\tt test} (not made by default) which will be cleaned
up automatically with \verb+make clean+.  The final line
specifies a dependency of certain object files on various header
files.

In gory detail, a makefile for a module must
\begin{enumerate}
\item include \verb+../config/makefile.h+ --- amoung other things this will
    define {\tt TARGET} from which any machine dependent actions are driven
    (if you don't need to use {\tt TARGET} then it's best to include this
     file at the same point that makelib.h is included).
\item define {\tt LIBRARY} as the name of the library to be made
\item optionally define {\tt OBJ} as the list of object files to be made 
    without optimization
\item optionally define {\tt OBJ\_OPTIMIZE} as the list of object files to 
    be made with optimization.  It is good practice to keep this list 
    short so as to minimize exposure to possible compiler errors.
\item optionally define {\tt HEADERS} as the list of header/include files to be
    copied into the common include directory
\item optionally define {\tt LIB\_TARGETS} as any additional files made in
    this subdirectory that may need cleaning up
\item optionally define {\tt LIB\_DEFINES} as any additional defines for
   the C preprocessor (for both Fortran and C)
 \item optionally define {\tt LIB\_INCLUDES} as any additional include
   directories
\item optionally define {\tt SUBDIRS} as any subdirectories to build (note
  that makefiles in subdirectories will need to modify the paths to
  the include files)
\item optionally define {\tt USES\_BLAS} to be the list of FORTRAN files that
    need BLAS names converting between single and double (e.g., {\tt
      ddot} to  {\tt sdot})
\item include \verb+../config/makelib.h+.  The first rule in this file
     builds the library so there should be {\em no} targets before this.
\item define any additional targets (e.g., test programs)
\end{enumerate}

Notes:
\begin{enumerate}
\item  To modify the optimization being used specify on the command
  line {\tt C/FDEBUG} or {\tt C/FOPTIMIZE} to override the flags for the 
  {\tt OBJ} and {\tt OBJ\_OPTIMIZE} files respectively.  E.g.,
\begin{verbatim}
     make FDEBUG="-g -O1"
     make FOPTIMIZE="-O3 -Superfast -bugs" FDEBUG="-O1"
\end{verbatim}
\item  The library is now put directly into the NWChem library
  directory and the full path to the library (if needed by your
  makefile) is automatically put into the variable {\tt
    LIBRARY\_PATH}.
\item The object files are now put directly into the libraries and are
  not kept elsewhere.  This has several implications
  \begin{itemize}
  \item You can (apart from TCGMSG and GA which are being fixed) build
    executables and libraries for multiple platforms in the same
    source tree.
  \item To force recompilation of all source in a given directory 
    \verb+make clean+ now works by deleting the object files from
    the library, and deletes the library itself only if it is empty.
    You have to
    actually either delete the corresponding library or touch the
    source files.
  \item To override the compilation options for a specifc file (e.g.,
    because of compiler errors on a specific platform) you must
    specify the dependency on the object file in the library.  Here
    are two examples.  The first one (\verb+dosymops.f+) does not need
    preprocessing, whereas the second one (\verb+sym_mo_ap_op.F+) does
    and this must done explicity within the rule for this file.
    This preprocessing is normally done automatically.
\begin{verbatim}
  ifeq ($(TARGET),CRAY-T3D)
    FNOOPT = -dp -Ccray-t3d -Wf"-o noscalar,jump,noieeedivide"
  $(LIBRARY_PATH)(dosymops.o):  dosymops.f
        $(FC) -c $(FNOOPT) $^
  $(LIBRARY_PATH)(sym_mo_ap_op.o):  sym_mo_ap_op.F
        $(FCONVERT)
        $(FC) -c $(FNOOPT) sym_mo_ap_op.f
        @/bin/rm -f sym_mo_ap_op.f
  endif
\end{verbatim}
  \end{itemize}
\item The target {\tt clean} will recursively descend subdirectories and
  delete object files from both the directory and associated library, 
  core files and files defined in {\tt LIB\_TARGETS}.
\item The target {\tt realclean} will, in addition to the actions of
  clean, also delete the library and any emacs backup files.
\item The target {\tt cleanF} will recursively descend subdirectories
  and search for and delete \verb+.f+ files for which a corresponding
  \verb+.F+ file exists.  This is useful on machines for which the
  conversion from \verb+.F+ to \verb+.f+ is done explicitly rather
  than by the compiler.
\item The target {\tt depend} will recursively descend subdirectories
  and append onto the end of makefiles dependencies of \verb+.F+ and
  \verb+.c+ files on header files that have been included using the
  notation \verb+#include "filename"+.  Files included using angle
  brackets are assumed to be system files and dependencies are not
  generated.  If the include file is in the local directory, the
  dependency is generated upon that.  Otherwise, a dependency is
  generated upon a file in the NWChem include directory.
  Do not insert anything below the line
\begin{verbatim}
# DO NOT EDIT BENEATH THIS LINE ... GENERATED AUTOMATICALLY
\end{verbatim}
  since it will be lost the next time that \verb+make depend+
  is run.
\end{enumerate}

Typing {\tt make} in the top-level NWChem directory will traverse the
entire directory tree twice.  Once to ensure the include files are
up-to-date, and again for the libraries.  This can take a while.
When developing a module, then unless recompilation of another module
is necessary, it is much faster to 
\begin{enumerate}
\item execute {\tt make} in the subdirectory, and
\item execute {\tt make link} in the top NWChem directory.
\end{enumerate}
The special target link just relinks the code and does not traverse
the directory tree.  {\em After doing a \verb+cvs update+ you should:}
\begin{enumerate}
\item do a make depend, if you have not recently, in any directory you
  have been working in, and
\item do a full make from the top level to ensure that all libraries
  incorporate any changed common blocks or declarations.
\end{enumerate}

In addition, the top-level makefile has the target {\tt test} which
builds the executable \verb+nwchem_test+ in the \verb+src/+ directory
(rather than the usual \verb+$(BINDIR)/nwchem+), and the target {\tt prof} 
which builds \verb+nwchem_prof+ (in \verb+src/+)
for performance profiling by linking with the -p option.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Inserting new modules into NWChem}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This is being redesigned.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Common Programmer Errors}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Use of TCGMSG global operation routines}

In some cases (notably workstation clusters) the global array tools
use a ``data-server'' process on each node in addition to the compute
processes.  Data-server processes don't follow the same flow of
execution of compute processes, so TCGMSG global operations
(\verb+brdcst+, \verb+igop+, and \verb+dgop+) will hang when invoked.
The global array toolkit provides ``wrapper'' functions
(\verb+ga_brdcst+, \verb+ga_igop+, and \verb+ga_dgop+) which properly
exclude data server processes from the global communication and must
be used instead of the corresponding TCGMSG functions.

\subsection{Interaction between GA and message-passing}

The limited buffering available on the IBM SP-1/2 means that GA and
message-passing operations cannot interleave as readily as they do on
other machines.  Basically, in transitioning from GA to message
passing or vice versa the application must call {\tt ga\_sync()}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The memory allocator --- MA}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sloppy
For detailed information on routines see the MA man pages by adding
{\tt \$(NWCHEM\_TOP)/src/man/ma/man} % $ 
to your {\tt MANPATH}.

\fussy

MA is a library of routines that comprises a dynamic memory allocator
for use by C, FORTRAN, or mixed-language applications.  FORTRAN
applications require such a library because the language does not
support dynamic memory allocation.  C applications can benefit from
using MA instead of the ordinary {\tt malloc()} and {\tt free()}
routines because of the extra features MA provides: both heap and
stack memory management disciplines, debugging and verification
support, usage statistics, and quantitative memory availability
information.  MA is designed to be portable across a large variety of
platforms.

\subsection{Typing}

\subsection{MA data types}

All MA memory is typed.  Data is allocated in units of integer,
logical, double precision, etc., words.  The type of data is specified
in arguments using predefined Fortran parameters (or macros in C).
\begin{description}
\item{\verb+MT_INT+} --- integer
\item{\verb+MT_DBL+} --- double precision
\item{\verb+MT_LOG+} --- logical
\item{\verb+MT_CHAR+} --- character\verb+*+1
\end{description}

\subsection{List of routines}

All MA routines are shown below, grouped by category and listed
alphabetically within each category.  The FORTRAN interface is given
({\em or the plan is to include it eventually}),
refer to the man pages for the C interface or information on the
arguments.

Initialization: 
\begin{itemize}
\item {\tt MA\_init(datatype, nominal\_stack, nominal\_heap)}
\item {\tt MA\_sizeof(datatype1, nelem1, datatype2)}
\item {\tt MA\_sizeof\_overhead(datatype)}
\end{itemize}

Allocation:
\begin{itemize}
\item {\tt MA\_alloc\_get(datatype, nelem, name, memhandle, index)}
\item {\tt MA\_allocate\_heap(datatype, nelem, name, memhandle)}
\item {\tt MA\_get\_index(memhandle, index)}
\item {\tt MA\_get\_pointer()} --- C only
\item {\tt MA\_inquire\_avail(datatype)}
\item {\tt MA\_inquire\_heap(datatype)}
\item {\tt MA\_inquire\_stack(datatype)}
\item {\tt MA\_push\_get(datatype, nelem, name, memhandle, index)}
\item {\tt MA\_push\_stack(datatype, nelem, name, memhandle)}
\end{itemize}

Deallocation:
\begin{itemize}
\item {\tt MA\_chop\_stack(memhandle)}
\item {\tt MA\_free\_heap(memhandle)}
\item {\tt MA\_pop\_stack(memhandle)}
\end{itemize}

Debugging:
\begin{itemize}
\item {\tt MA\_set\_auto\_verify()}
\item {\tt MA\_set\_error\_print()}
\item {\tt MA\_set\_hard\_fail()}
\item {\tt MA\_summarize\_allocated\_blocks()}
\item {\tt MA\_verify\_allocator\_stuff()}
\end{itemize}

Iteration Over Allocated Blocks:
\begin{itemize}
\item {\tt MA\_get\_next\_memhandle(ithandle, memhandle)}
\item {\tt MA\_init\_memhandle\_iterator(ithandle)}
\end{itemize}

Statistics:
\begin{itemize}
\item {\tt MA\_print\_stats(oprintroutines)}
\end{itemize}


\subsection{Errors}

Errors considered fatal by MA result in program termination.  Errors
considered nonfatal by MA cause the MA routine to return an error
value to the caller.  For most boolean functions, false is returned
upon failure and true is returned upon success.  (The boolean
functions for which the return value means something other than
success or failure are {\tt MA\_set\_auto\_verify()}, {\tt
  MA\_set\_error\_print()}, and {\tt MA\_set\_hard\_fail()}.)  Integer
functions return zero upon failure; depending on the function, zero
may or may not be distinguishable as an exceptional value.

An application can force MA to treat all errors as fatal via
{\tt MA\_set\_hard\_fail()}.

If a fatal error occurs, an error message is printed on the standard
error (stderr).  By default, error messages are also printed for
nonfatal errors.  An application can force MA to print or not print
error messages for nonfatal errors via {\tt MA\_set\_error\_print()}.

\subsection{Files}

To access required MA definitions, C applications should include
{\tt macdecls.h} and FORTRAN applications should include
{\tt mafdecls.fh}.

\subsection{Implementation}

Memory layout definitions:
\begin{itemize}
\item segment = heap\_region stack\_region
\item region = block block block \ldots
\item block = AD gap1 guard1 client\_space guard2 gap2
\end{itemize}

A segment of memory is obtained from the OS upon initialization.  The
low end of the segment is managed as a heap; the heap region grows
from low addresses to high addresses.  The high end of the segment is
managed as a stack; the stack region grows from high addresses to low
addresses.

Each region consists of a series of contiguous blocks, one per
allocation request, and possibly some unused space.  Blocks in the
heap region are either in use by the client (allocated and not yet
deallocated) or not in use by the client (allocated and already
deallocated).  A block on the rightmost end of the heap region becomes
part of the unused space upon deallocation.  Blocks in the stack
region are always in use by the client, because when a stack block is
deallocated, it becomes part of the unused space.

A block consists of the client space, i.e., the range of memory
available for use by the application; guard words adjacent to each end
of the client space to help detect improper memory access by the
client; bookkeeping info (in an "allocation descriptor," AD); and two
gaps, each zero or more bytes long, to satisfy alignment constraints
(specifically, to ensure that AD and client\_space are aligned
properly).  


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The runtime database --- RTDB}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

NWchem consists of independent modules (e.g., input, SCF, RIMP2) that
communicate through a database (similar in spirit to the GAMESS
dumpfile or the Gaussian checkpoint file).  The only way modules can
share data is via the database, or via files whose names are stored in
the database (which may have default values).  Everything stored
directly in the database comprises a typed array described by
\begin{enumerate}
\item a name which is a simple string of ASCII characters (e.g., 
      \verb+"reference energies"+),
\item the type of the data (real, integer, logical, or character), 
\item the number of data items, and
\item the actual data (an array of items of the specified type).
\end{enumerate}

A database is simply a file and is openend by name. Usually there is
just one database per calculation, though multiple databases may be
open at any instant.  

By default access to all open databases occur in parallel, meaning
that
\begin{itemize}
\item all processes must participate in any read/write of any database
  and any such operation has an implied synchronization
\item writes to the database write the data associated with process
  zero but the correct status of the operation is returned to all
  processes
\item reads from the database read the data named by process zero and
  broadcast the data to all processes, checking dimensions and types
  of provided arrays
\end{itemize}

Alternatively, database operations can occur sequentially, meaning
that
\begin{itemize}
\item only process zero can read/write the database and this happens
  with no communication or synchronization with other processes
\item read/write operations by any other process than process zero is
  an error
\end{itemize}

Usually, all processes will want the same data at the same time from
the database, and all processes will want to know of the success or
failure of operations.  This is readily done in the default parallel
mode.  A counter-example to this is provided during the reading of input.
Usually, only process zero will read the input and needs to store the
data directly into the database without involving the other processes.
This is done using sequential mode.

Following is a detailed listing of the C and Fortran API\@.  
Programs using RTDB routines should include the appropriate Fortran
({\tt rtdb.fh}) or C ({\tt rtdb.h}) header file.   These define return
types for all functions and also the paramters 
\begin{itemize}
\item {\tt rtdb\_max\_key} --- an integer parameter that defines the maximum
  length of a character string key
\item {\tt rtdb\_max\_file} --- an integer parameter that defines the maximum
  length of a file name
\end{itemize}
All routines return \TRUE (1 in C) on success, \FALSE (0
in C) on failure.

\subsection{{\tt rtdb\_parallel}}
\begin{verbatim}
  int rtdb_parallel(const int mode)

  logical function rtdb_parallel(mode)
  logical mode              [input]
\end{verbatim}
Set the parallel access mode of all databases to mode and return the
previous setting. If {\tt mode} is true then accesses are in parallel.

\subsection{{\tt rtdb\_open}}
\begin{verbatim}
  int rtdb_open(const char *filename, const char *mode, int *handle)

  logical function rtdb_open(filename, mode, handle)
  character *(*) filename   [input]
  character *(*) mode       [input]
  integer handle            [output]
\end{verbatim}
Open a database:
\begin{itemize}
\item    {\tt Filename} --- path to file associated with the data base
\item    {\tt mode} ---
\begin{itemize}
\item {\tt new} ---  Open only if it does not exist already
\item {\tt old} ---  Open only if it does exist already
\item {\tt unknown} --- Create new or open existing (preserving contents)
\item {\tt empty} --- Create new or open existing (deleting contents)
\item {\tt scratch} --- Create new or open existing (deleting contents)
                         and automatically delete upon closing.  Also, items
                         cached in memory are not written to disk.
\end{itemize}
\item {\tt handle} --- returns an integer handle by which all future
  references to the data base are made
\end{itemize}

\subsection{{\tt rtdb\_close}}
\begin{verbatim}
  int rtdb_close(const int handle, const char *mode)

  logical function rtdb_close(handle, mode)
  integer handle            [input]
  character*(*) mode        [input]
\end{verbatim}
Close a database:
\begin{itemize}
\item {\tt handle} --- handle to RTDB
\item {\tt mode} ---
\begin{itemize}
\item {\tt keep} ---    Preserve the data base file to enable restart
\item {\tt delete} ---  Delete the data base file freeing all resources
\end{itemize}
\end{itemize}
The {\tt mode} of close is overridden by opening the data base with
{\tt mode} equal to {\tt scratch} in which instance it is always
deleted upon closing.

\subsection{{\tt rtdb\_put}}
\begin{verbatim}
  int rtdb_put(const int handle, const char *name, const int ma_type,
               const int nelem, const void *array)

  logical function rtdb_put(handle, name, ma_type, nelem, array)
  integer handle            [input]
  character *(*) name       [input]
  integer ma_type           [input]
  integer nelem             [input]
  <ma_type>array(nelem)     [input]
\end{verbatim}
Insert an entry into the data base replacing previous entry
\begin{itemize}
\item {\tt handle} --- handle to RTDB
\item {\tt name} --- entry name (null terminated character string)
\item {\tt ma\_type} --- MA type of the entry
\item {\tt nelem} --- number of elements of the given type
\item {\tt array} --- data to be inserted
\end{itemize}

\subsection{{\tt rtdb\_get}}
\begin{verbatim}
  int rtdb_get(const int handle, const char *name, const int ma_type,
               const int nelem, void *array)

  logical function rtdb_get(handle, name, ma_type, nelem, array)
  integer handle            [input]
  character *(*) name       [input]
  integer ma_type           [input]
  integer nelem             [input]
  <ma_type>array(nelem)     [output]
\end{verbatim}
Get an entry from the data base
\begin{itemize}
\item {\tt handle} --- handle to RTDB
\item {\tt name} --- entry name
\item {\tt ma\_type} --- MA type of the entry which must match entry type
\item {\tt nelem} --- size of array in units of {\tt ma\_type}
\item {\tt array} --- user provided buffer that returns data
\end{itemize}

\subsection{{\tt rtdb\_cput/get}}
\begin{verbatim}
  logical function rtdb_cput(handle, name, nelem, buf)
  integer handle            [input]
  character *(*) name       [input]
  character *(*) buf        [input]

  logical function rtdb_cget(handle, name, nelem, buf)
  integer handle            [input]
  character *(*) name       [input]
  character *(*) buf        [output]
\end{verbatim}
Fortran routines to provide put/get functionality for character
variables.

\subsection{{\tt rtdb\_ma\_get}}
\begin{verbatim}
  int rtdb_ma_get(const int handle, const char *name, int *ma_type,
                  int *nelem, int *ma_handle)

  logical function rtdb_ma_get(handle, name, ma_type, nelem, ma_handle)
  integer handle            [input]
  character *(*) name       [input]
  integer ma_type           [output]
  integer nelem             [output]
  integer ma_handle         [output]
\end{verbatim}
Get an entry from the data base returning an MA handle to memory
automatically allocated to hold the data read from the database.
\begin{itemize}  
\item {\tt handle} --- handle to RTDB
\item {\tt name} --- entry name
\item {\tt ma\_type} --- returns MA type of the entry
\item {\tt nelem} --- returns number of elements of type {\tt ma\_type} in data
\item {\tt ma\_handle} --- returns MA handle to data
\end{itemize}


\subsection{{\tt rtdb\_get\_info}}
\begin{verbatim}
  int rtdb_get_info(const int handle, const char *name, int *ma_type, 
                    int *nelem, char date[26])

  logical function rtdb_get_info(handle, name, ma_type, nelem, date)
  integer handle            [input]
  character *(*) name       [input]
  integer ma_type           [output]
  integer nelem             [output]
  character*26 date         [output]
\end{verbatim}
Get info about an entry from the data base
\begin{itemize}
\item {\tt handle} ---- handle to RTDB
\item {\tt name} --- entry name (null terminated character string in
  C,  standard FORTRAN character constant or variable in FORTRAN)
\item {\tt ma\_type} --- returns MA type of the entry
\item {\tt nelem} --- returns number of elements of the given type
\item {\tt date} --- returns date of insertion (null terminated
  character string, or FORTRAN character variable)
\end{itemize}

\subsection{{\tt rtdb\_first/next}}
\begin{verbatim}
  int rtdb_first(const int handle, const int namelen, char *name)

  int rtdb_next(const int handle, const int namelen, char *name)

  logical function rtdb_first(handle, name)
  integer handle            [input]
  character *(*) name       [output]

  logical function rtdb_next(handle, name)
  integer handle            [input]
  character *(*) name       [output]
\end{verbatim}
These routines enable iteration through the items in the database in
an effectively random order.  They return in {\tt name} the name of
the first/next (user inserted) entry in the data base. 
\begin{itemize}
\item {\tt handle} --- handle to RTDB
\item {\tt namelen} ---  size of user provided buffer name (C only)
\item {\tt name} --- name of first/next entry is returned in this
  buffer
\end{itemize}

An example of their use in C to count and print the name of all
entries is
\begin{verbatim}
  char name[256];
  int n, status, rtdb;

  for (status=rtdb_first(rtdb, sizeof(name), name), n=0;
       status;
       status=rtdb_next(rtdb, sizeof(name), name), n++) 
    printf("entry %d has name '%s'\n", n, name);
\end{verbatim}

\subsection{{\tt rtdb\_delete}}
\begin{verbatim}
  int rtdb_delete(const int handle, const char *name)

  logical function rtdb_delete(handle, name)
  integer handle            [input]
  character *(*) name       [input]
\end{verbatim}
Delete the entry from the database. 
\begin{itemize}
\item {\tt handle} --- handle to RTDB
\item {\tt name} --- name of entry to delete
\end{itemize}
Returns
\begin{itemize}
\item 1 if key was present and successfully deleted, or
\item 0 if key was not present, or if an error occured.
\end{itemize}

\subsection{{\tt rtdb\_print}}
\begin{verbatim}
  int rtdb_print(const int handle, const int print_values)

  logical function rtdb_print(handle, print_values)
  integer handle            [input]
  logical print_values      [input]
\end{verbatim}
Print the contents of the data base to {\tt STDOUT}.
\begin{itemize}
\item {\tt handle} --- handle to RTDB
\item {\tt print\_values} --- boolean flag --- if true values as
  well as keys are printed out.
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Global Arrays --- GA}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sloppy
For more detailed information look in 
{\tt \$NWCHEM\_TOP/src/global/doc/global.doc}     %$ for emacs

\fussy

Globally addressable arrays have been developed to simplify writing
portable scientific software for both shared and distributed memory
computers.  Programming convenience, code extensibility and
maintainability are gained by adopting the shared memory programming
model.

From the user perspective, a global array can be used as it was stored
in the shared memory. Details of the data distribution, addressing and
communication are encapsulated in the global array objects. However,
the information on the actual data distribution can be obtained and
taken advantage of whenever data locality is important.

Currently support is limited to 2-D double precision or integer arrays
with block distribution, at most one block per array per processor.

Operations that are globally collective \ldots i.e.\ must be
simultaneously invoked by all processes as if in SIMD mode:
\begin{itemize}
\item {\tt ga\_initialize} --- initialize global array internal
  structures
\item {\tt ga\_initialize\_ltd} --- initialize global arrays and set
  memory usage limits
\item {\tt ga\_create} --- create an array
\item {\tt ga\_create\_irreg} --- create an array with irregular
  distribution
\item {\tt ga\_duplicate} --- create an array following a reference
  array
\item {\tt ga\_destroy} --- destroy an array
\item {\tt ga\_terminate} --- destroy all existing arrays and delete
  internal data structures
\item {\tt ga\_sync} --- synchronize processes (a barrier)
\item {\tt ga\_zero} --- zero an array
\item {\tt ga\_ddot} --- dot product of two arrays (doubles only)
\item {\tt ga\_dscal} --- scale the elements in an array by a constant
  (double precision data only)
\item {\tt ga\_dadd} --- scale and add two arrays to put result in a
  third (may overwrite one of the other two, doubles only)
\item {\tt ga\_copy} --- copy one array into another
\item {\tt ga\_dgemm} --- BLAS-like matrix multiply
\item {\tt ga\_ddot\_patch} --- dot product of two arrays (doubles
  only) (patch version)
\item {\tt ga\_dscal\_patch} --- scale the elements in an array by a
  constant (patch version)
\item {\tt ga\_dadd\_patch} --- scale and add two arrays to put result
  in a third (patch version)
\item {\tt ga\_ifill\_patch} --- fill a patch of array with value
  (integer version)
\item {\tt ga\_dfill\_patch} --- fill a patch of array with value
  (double version)
\item {\tt ga\_matmul\_patch} --- matrix multiply (patch version)
\item {\tt ga\_diag} --- real symmetric generalized eigensolver
  (sequential version also exists)
\item {\tt ga\_diag\_reuse} --- a version of ga\_diag for repeated use
\item {\tt ga\_diag\_std} --- standard real symmetric eigensolver
  (sequential version also exists)
\item {\tt ga\_symmetrize} --- symmetrize a matrix
\item {\tt ga\_transpose} --- transpose a matrix
\item {\tt ga\_lu\_solve} --- solve system of linear equations based
  on LU factorization (sequential version also exists)
\item {\tt ga\_print\_patch} --- print a patch of an array to the
  screen
\item {\tt ga\_print} --- print an entire array to the screen
\item {\tt ga\_copy\_patch} --- copy data from a patch of one global
  array into another array
\item {\tt ga\_compare\_distr} --- compare distributions of two global
  arrays
\end{itemize}

Operations that may be invoked by any process in true MIMD style:
\begin{itemize}
\item {\tt ga\_get} --- read from a patch of an array
\item {\tt ga\_put} --- write to a patch of an array
\item {\tt ga\_acc} --- accumulate into a patch of an array (double
  precision only)
\item {\tt ga\_scatter} --- scatter elements into an array
\item {\tt ga\_gather} --- gather elements from an array
\item {\tt ga\_read\_inc} --- atomically read and increment the value
  of a single array element (integers only)
\item {\tt ga\_locate} --- determine which process `holds' an array
  element
\item {\tt ga\_locate\_region} --- determine which process `holds' an
  array section
\item {\tt ga\_error} --- print error message and terminate the
  program
\item {\tt ga\_summarize} --- print information about already
  allocated arrays
\end{itemize}

Operations that may be invoked by any process in true MIMD style and
are intended to support writing of new functions:
\begin{itemize}
\item {\tt ga\_distribution} --- find coordinates of the array patch
  that is `held' by a processor
\item {\tt ga\_access} --- access internal data
\item {\tt ga\_release} --- relinquish access to internal data
\item {\tt ga\_release\_update} --- relinquish access after data were
  updated
\item {\tt ga\_check\_handle} --- verify that a GA handle is valid
\end{itemize}

Operations to support portability between implementations:
\begin{itemize}
\item {\tt ga\_nodeid} --- find requesting compute process message id
\item {\tt ga\_nnodes} --- find number of compute processes
\item {\tt ga\_dgop} --- equivalent to TCGMSG dgop
\item {\tt ga\_igop} --- equivalent to TCGMSG igop
\item {\tt ga\_brdcst} --- equivalent to TCGMSG brdcst
\end{itemize}

Other utility operations:
\begin{itemize}
\item {\tt ga\_inquire} --- find the type and dimensions of the array
\item {\tt ga\_inquire\_name} --- find the name of the array
\item {\tt ga\_inquire\_memory} --- find the amount of memory in
  active arrays
\item {\tt ga\_memory\_avail} --- find the amount of memory left for
  GA
\item {\tt ga\_summarize} --- prints summary info about allocated
  arrays
\item {\tt ga\_uses\_ma} --- finds if memory in arrays comes from MA
  (memory allocator)
\item {\tt ga\_memory\_limited} --- finds if limits were set for
  memory usage in arrays
\end{itemize}

Note that consistency is only guaranteed for
\begin{enumerate}
\item Multiple read operations (as the data does not change)
\item Multiple accumulate operations (as addition is commutative)
\item Multiple disjoint put operations (as there is only one writer
  for each element)
\end{enumerate}
The application has to worry about everything else (usually by
appropriate insertion of {\tt ga\_sync} calls).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Free-format Fortran input routines --- INP}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

 All routines are declared in the header file {\tt inp.fh}.
Have a look at the input routines in the NWChem input module
for code examples.

\subsection{Initialization}

\subsubsection{{\tt inp\_init}}

\begin{verbatim}
  subroutine inp_init(ir, iw)
  integer ir, iw     [input]
\end{verbatim}
Initialize free format input routines to take input from Fortran unit
{\tt ir} and send their output to fortran unit {\tt iw}.  The input
file is processed from the current location.

{\tt inp\_init()} shuld be invoked each time the input file is
repositioned using other than {\tt inp\_*()} routines (e.g., rewind).

\subsection{Basic input routines}

\subsubsection{{\tt inp\_read}}
\begin{verbatim}
  logical function inp_read()
\end{verbatim}
Read a line from the input and split it into white space (blank or
tab) separated fields.  White space may be incorporated into a field
by enclosing it in quotes (\verb+"+).  The case of input is preserved.
Blank lines are ignored, and text from a pound or hash symbol
(\verb+#+) to the end of the line is treated as a comment.  A
backslash(\verb+\+) at the end of a line (only white space may appear
after it) may be used to concatentate physical input lines into one
logical input line.  A semicolon (\verb+;+) may be used to split a
physical input line into multiple logical input lines.  The special
meaning of hash (\verb+#+), semicolon (\verb+;+) and quotation
(\verb+"+) characters may be avoided only by prefacing them with a
backslash (this must be done even if the character is inside a quoted
character string).

The number of fields read is set to 0, there being a total of
\verb+inp_n_field()+ fields in the line.

If a non-blank line is successfully parsed then \TRUE is returned.
Otherwise an internal error message is set and \FALSE is returned.

Possible errors include detection of EOF ({\tt inp\_eof()} may be used to
check for this condition) or failure to parse the line (e.g., a
character string without a terminating quote).

EOF may be indicated by end of the physical input file, or by a
physical input line that begins with either asterisk (*), period (\.)
or EOF (ignoring case), and has only trailing white space.

There is a maximum input line width of 1024 characters.

\subsubsection{{\tt inp\_i}}
\begin{verbatim}
  logical function inp_i(i)
  integer i        [output]
\end{verbatim}
Attempt to read the next field as an integer.  Upon success return
\TRUE and advance to the next field.  Otherwise return \FALSE,
save an internal error message and do not change the
current field.  The input argument ({\tt i}) is not changed unless an
integer is successfully read (so that any default value already
present in i is not corrupted).

\subsubsection{{\tt inp\_f}}
\begin{verbatim}
  logical function inp_f(d)
  double precision d       [output]
\end{verbatim}
Attempt to read the next field as a floating point number.  Upon
success return \TRUE and advance to the next field.  Otherwise
return \FALSE, save an internal error message and do not change
the current field.  The input argument ({\tt d}) is not changed unless
an integer is successfully read (so that any default value already
present in {\tt d} is not corrupted).

\subsubsection{{\tt inp\_a}}
\begin{verbatim}
  logical function inp_a(a)
  character *(*) a         [output]
\end{verbatim}
Attempt to read the next field as a character string.  Upon success
return \TRUE and advance to the next field.  Otherwise return
\FALSE, save an internal error message and do not change the
current field.

\subsubsection{{\tt inp\_a\_trunc}}
\begin{verbatim}
  logical function inp_a_trunc(a)
  character *(*) a         [output]
\end{verbatim}
Attempt to read the next field as a character string, quietly
discarding any data that does not fit in the user provided buffer.
Upon success return \TRUE and advance to the next field.
Otherwise return \FALSE, save an internal error message and do
not change the current field.

\subsubsection{{\tt inp\_line}}
\begin{verbatim}
  logical function inp_line(z)
  character*(*) z          [output]
\end{verbatim}
Return in {\tt z} as much of the entire input line as it will hold and
quietly discard any overflow.  Upon success return \TRUE,
otherwise save an internal error message and return \FALSE

\subsubsection{{\tt inp\_cline}}
\begin{verbatim}
  subroutine inp_cline(z, len, success)
  character*(*) z          [output]
  integer len              [input]
  logical success          [input]
\end{verbatim}
A C-callable equivalent of inp\_line, which puts {\tt len -1} characters of
the input line into the character string {\tt z}. Trailing spaces are
eliminated and the string is terminated with a 0 character, as is
standard for C,


\subsubsection{{\tt inp\_irange}}
\begin{verbatim}
  logical function inp_irange(first, last, stride)
  integer first, last, stride     [output]
\end{verbatim}
Attempt to read the next field as a Fortran90-style triplet specifying
a range with optional stride.  Upon success return \TRUE and
advance to the next field.  Otherwise, return \FALSE, save
internal error message, and do not change the current field.  The
input arguments are not changed unless an integer range is
successfully read.

The syntax is \verb+<first>[:<last>[:<stride>]]+, where all terms are
integers.  The default \verb+<stride>+ is 1.  A simple integer is, in
essence, a degenerate triplet, and will be read correctly by this
routine.  The result will be as if the input had been
\verb+"<first>:<first>:1"+.

\subsubsection{{\tt inp\_ilist}}
\begin{verbatim}
  logical function inp_ilist(maxlist, list, n)
  integer maxlist          [input]
  integer list(maxlist)    [output]
  integer n                [output]
\end{verbatim}
Reads the remainder of the line as a list of integers and puts the
results in {\tt list}.  Ranges of integers may be input compactly
using the notation of \verb+inp_irange()+. The number of elements set
from the input is returned in \verb+n+.

\verb+inp_ilist+ returns \TRUE if the input is a valid integer
list, and \FALSE otherwise, also setting an appropriate error
message.  If $n > $ ~{\tt maxlist}, it indicates that there is too
much data on the line to fit in {\tt list}.

\subsubsection{{\tt inp\_search}}
\begin{verbatim}
  logical function inp_search(ocase, z, nz)
  logical ocase            [input]
  integer nz               [input]
  character*(*) z(nz)      [input]
\end{verbatim}
Position the input file at the next logical input line which has a
first input field that matches the leading non-blank characters of one
of the elements of \verb+z+.  If ocase is \TRUE then matches are case
sensitive.

If such a line is found then return \TRUE, and reset the
current input field to 0 (i.e., as if \verb+inp_read()+ had just been
called).

If no such line is found return \FALSE\@.  The file will be
either at EOF or at a line which was not successfully parsed.  EOF may
be detected by \verb+inp_eof()+.

\subsection{Routines concerning fields within a line}

\subsubsection{{\tt inp\_n\_field}}
\begin{verbatim}
  integer function inp_n_field()
\end{verbatim}
Returns the number of fields in the current input line (1, \ldots).  A
value of 0 implies either that EOF or some other error was detected or
{\tt inp\_read()} has not yet been called.

\subsubsection{{\tt inp\_cur\_field}}
\begin{verbatim}
  integer function inp_cur_field()
\end{verbatim}
Returns the number of fields in the input line that have been processed
so far (0, \ldots).  Thus if {\tt inp\_cur\_field()} returns 2, then the next
field read by {\tt inp\_f()} etc.\ will be field 3.

\subsubsection{{\tt inp\_set\_field}}
\begin{verbatim}
  subroutine inp_set_field(value)
  integer value            [input]
\end{verbatim}
Sets the current field (as returned by \verb+inp_cur_field+) to be
value.  $0 \le$~{\tt value}~$\le$ {\tt inp\_n\_field()}.  An out of
range value results in error termination.

\subsubsection{{\tt inp\_prev\_field}}
\begin{verbatim}
  subroutine inp_prev_field()
\end{verbatim}
A convenience routine that positions you to read the field (on the
current input line) that was last read.  It is simply implemented as
\begin{verbatim}
        call inp_set_field(max(0,inp_cur_field()-1))
\end{verbatim}
At the beginning of the line this is a null operation.


\subsection{String routines}
These routines don't actually read input but are helpful in
interpreting input or formatting output.

\subsubsection{{\tt inp\_strlen}}
\begin{verbatim}
  integer function inp_strlen(z)
  character*(*) z          [input]
\end{verbatim}
Return the index of the last non-blank character in {\tt z}, 0 being
returned for a fully blank string.

\subsubsection{{\tt inp\_lcase}}
\begin{verbatim}
  subroutine inp_lcase(z)
  character*(*) z          [input/oputput]
\end{verbatim}
Lowercase the character string {\tt z}.

\subsubsection{{\tt inp\_ucase}}
\begin{verbatim}
  subroutine inp_ucase(z)
  character*(*) z          [input/output]
\end{verbatim}
Uppercase the character string {\tt z}.

\subsubsection{{\tt inp\_compare}}
\begin{verbatim}
  logical function inp_compare(ocase, a, b)
  logical ocase            [input]
  character*(*) a, b       [input]
\end{verbatim}
Return \TRUE iff all the characters in A match the first len(A)
characters of B.  If ocase is \TRUE then comparisons are case
sensitive, otherwise comparisons ignore case.

\subsubsection{{\tt inp\_match}}
\begin{verbatim}
  logical function inp_match(nrec, ocase, test, array, ind)
  integer nrec             [input]
  logical ocase            [input]
  character*(*) test       [input]
  character*(*) array(nrec)[input]
  integer ind              [output]
\end{verbatim}
Let {\tt L} be the length of the character string test ignoring
trailing blanks.  Attempt to find a unique match of \verb+test(1:L)+
against elements of \verb+array(*)+.  If \verb+ocase+ is \TRUE then
comparisons are case sensitive, otherwise comparisons ignore case.

If a unique match is made return the index of the element in
\verb+ind+ and return \TRUE

If the match is ambiguous set \verb+ind+ to 0, and return \FALSE.

If no match is found set \verb+ind+ to -1 and return \FALSE.

\subsubsection{{\tt inp\_strtok}}
\begin{verbatim}
  logical function inp_strtok(z, sep, istart, iend)
  character*(*) z           ! [input] string to parse
  character*(*) sep         ! [input] token separators
  integer istart, iend      ! [output] start/end of next token
\end{verbatim}
Returns the number of the start and end character of the next token in
the character string.  Tokens are separated by one of the characters
in \verb+sep+.  Note that all characters in \verb+sep+ are used including any
trailing blanks.

Before the first call initialize \verb+istart+ to zero, and leave
\verb+istart+ and \verb+iend+ {\em unchanged} for subsequent calls.
Repeated calls return the next token and \TRUE, or \FALSE if there are
no more tokens.  The separators may be changed between calls.  No
internal state is maintained (which is why \verb+istart+ and
\verb+iend+ must not be modified between calls) so multiple strings
may be parsed simultaneously.

E.g., to split the character string \verb+list+ into tokens separated 
by \verb+':'+ and print each token out, you might execute
\begin{verbatim}
     istart = 0
  10 if (inp_strtok(list, ':', istart, iend)) then
        write(6,*) list(istart:iend)
        goto 10
     endif
\end{verbatim}

\subsection{Error handling routines}

\subsubsection{{\tt inp\_errout}}
\begin{verbatim}
  subroutine inp_errout()
\end{verbatim}
If there is an internal error message, print out its value, the
current line number and its contents.  If appropriate indicate the
problematic position in the current input line.

\subsubsection{{\tt inp\_outrec}}
\begin{verbatim}
  subroutine inp_outrec()
\end{verbatim}
Print out the current input line.

\subsubsection{{\tt inp\_clear\_err}}
\begin{verbatim}
  subroutine inp_clear_err()
\end{verbatim}
Clear error conditions and messages that may no longer be relevant.
For instance, if values are read from a line until no more are
available, the error message ``at end of line looking for \ldots''
will be internally recorded.  A call to this routine will clear this state.

\subsubsection{{\tt inp\_eof}}
\begin{verbatim}
  logical function inp_eof()
\end{verbatim}
Return \TRUE if EOF has been detected, \FALSE otherwise.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Print control}
\label{sec:print}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

All modules should use the same print control mechanism to provide
both uniformity and flexibility.  The routines in \verb+util_print+ do
this.  By using these routines

\begin{enumerate}
\item All modules understand the print levels
\begin{itemize}
\item \verb+none+
\item \verb+low+
\item \verb+medium+ = \verb+default+
\item \verb+high+
\item \verb+debug+
\end{itemize}
\verb+None+ is defined to mean literally no output except for
catastrophic errors (e.g., inconsistent data, failure to converge).
\item Printing of specific quantities may be directly enabled or
  disabled from the input using already existing input routines
\item Modules operate independently and printing will eventually be
   controllable via context
\end{enumerate}

This is an example of how it currently works. Inside the SCF input
\begin{verbatim}
  print low basis "final eigenvectors"
  noprint title
\end{verbatim}
This sets the overall SCF printlevel to low, forces printing of the
final eigenvectors and basis, and disables printing of the title.

The implementation is very simple.  Each module defines (using
provided input routines) one or two entries in the database which
enable/disable printing
\begin{itemize}
\item \verb+<module>:print+ --- list of names to enable print
\item \verb+<module>:noprint+ --- list of names to disable print
\end{itemize}
The special values ({\tt none}, {\tt low}, \ldots) are recognized in
the list of print keywords and are used to adjust the print level.
The parsing of this list is encapsulated in the routine
\verb+util_print_rtdb_load()+.  To support multiply nested modules a
stack of print options is maintained --- this will eventually be
combined with the mythical context.

\sloppy
The code necessary for a module using print control is then simply:
\begin{itemize}
\item In the input routine, upon detecting a line with either the print
  or noprint directive
\begin{verbatim}
     call util_print_input(rtdb, 'module_name')
\end{verbatim}
\item At the beginning of a module
\begin{verbatim}
     call util_print_push 
     call util_print_rtdb_load(rtdb, 'module_name')
\end{verbatim}
  \verb+util_print_push()+ sets the default printlevel for a new
  module. \verb+util_print_rtdb_load+ reads in any input parameters
\item To control printing within a module
\begin{verbatim}
     #include "util.fh"

     if (util_print("name", level)) then
       write out data associated with "name"
     endif
\end{verbatim}
  Level is one of the prespecified print levels (\verb+print_none+,
  \verb+print_low+, \ldots; see \verb+util/printlevels.fh+ for
  actual values).
\item At the end of a module
\begin{verbatim}
     call util_print_pop
\end{verbatim}
\end{itemize}

\fussy

 E.g.
\begin{verbatim}
#include "util.fh"

      call util_print_push
      call util_print_rtdb_load('scf')
      if (util_print('information', print_low)) then
         write(6,*) ...
      endif
      ...
      call util_print_pop
\end{verbatim}

 If an application wants more direct control over printing there are
routines to explicitly control the print level and to enable/disable
printing of named items.

{\tt util.fh} has been modified to define the integers
\begin{itemize}
\item \verb+print_none+ (use of this as an argument for
  \verb+util_print+ will force printing even if none is asked for!)
\item \verb+print_low+
\item \verb+print_medium+
\item \verb+print_high+
\item \verb+print_debug+
\item \verb+print_never+
\item \verb+print_default+ = \verb+print_medium+
\end{itemize}
and to declare \verb+util_print+ as an external logical valued function.

Other relevant routines are

\subsection{{\tt util\_print}}
\sloppy
\begin{verbatim}
  logical function util_print(level, name)
  integer level        [input]
  character*(*) name   [input]
\end{verbatim}
If \verb+level+ is less than or equal to the current print level
(which is set by either \verb+util_print_rtdb_load+, or
\verb+util_print_set_level+), or the printing of \verb+name+ was
explicitly enabled, and the printing of \verb+name+ has not been
explicitly disabled, then \TRUE is returned.  Otherwise
\FALSE is returned.

\fussy

\subsection{{\tt util\_print\_input}}
\begin{verbatim}
    subroutine util_print_input(rtdb, prefix)
    integer rtdb         [input]
    character*(*) prefix [input]
\end{verbatim}
The input routine of a module should call this routine upon detecting
either the {\tt print} or {\tt noprint} directives.  It should pass
the name of the module in the character string {\tt prefix}.  This is
prepended to actual entries made in the database.

\subsection{{\tt util\_print\_push}}
\begin{verbatim}
    subroutine util_print_push
\end{verbatim}
Call this routine on entry to a module to push the print stack down.
A call to this routine is usually immediately followed by a call to
\verb+util_print_rtdb_load+. 

\subsection{{\tt util\_print\_pop}}
\begin{verbatim}
    subroutine util_print_pop
\end{verbatim}
Call this routine immediately before exit from a module to pop the
print stack to the previous context.  Once context is properly
functioning the push/pop routines may disappear.

\subsection{{\tt util\_print\_rtdb\_load}}
\begin{verbatim}
    subroutine util_print_rtdb_load(rtdb, prefix)
    integer rtdb         [input]
    character*(*) prefix [input]
\end{verbatim}
This routine loads the print information from the database for a
module with name provided in \verb+prefix+.  The value of
\verb+prefix+ must match that provided in the corresponding call to
\verb+util_print_input+.

This routine is usually called at the start of a module immediately
following a call to \verb+util_print_push+.

\subsection{{\tt util\_print\_set\_level}}
\begin{verbatim}
    subroutine util_print_set_level(level)
    integer level        [input]
\end{verbatim}
Set the print level to {\tt level}.  This routine is rarely called
from applications.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The Geometry Object}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  `Geometry', unfortunately, is a bit of a misnomer since the
`geometry object' serves several purposes
\begin{itemize}
\item a definition of the coordinate system and positioning in space
  (also lattice vectors for periodic systems)
\item an association of names/tags with coordinates in space
\item a specification of the external potential (nuclear multipole
  moments, external fields, effective core potentials, \ldots) that
  defines the Hamiltonian for all electronic structure methods
\item The geometry is home for most Hamiltonian related information (and
  not wavefunction related information).
\end{itemize}

The tag associated with a geometric center is overloaded with many
different meanings
\begin{itemize}
\item an element (to provide default specification of nuclear charge,
  mass, number of electrons, \ldots)
\item as a name of an `atomic' basis set
\item as a test for symmetry equivalence (lower symmetry can be forced
     by specifying different tags for otherwise symmetry equivalent
     centers)
\item etc.
\end{itemize}

The data in (or derived from) the geometry object includes, or will
eventually include
\begin{enumerate}
\item A description of the coordinates of all types of centers (e.g.,
      atom, basis function)
\item Charges (eventually ECPs, \ldots) associated with those centers
\item Tags (names) of centers
\item Masses associated with centers
\item Variables for optimization (e.g., via constrained cartesians
      or zmatrix variables)
\item Symmetry information
\item Any other simple scalar/vector attributed associated
      specifically with a center
\end{enumerate}

Geometries are referenced through an integer handle.  In this fashion,
multiple geometries may be accessible at any instant, though since
geometries can consume a lot of memory the number of simultaneously
`open' geometries should be kept to a minimum.

All logical functions return true on sucess, false on failure.  Only
other actions are discussed below.

\subsection{Creating, destroying, loading and storing geometries}

\subsubsection{{\tt geom\_create}}
\begin{verbatim}
  logical function geom_create(geom, name)
  integer geom          [output]
  character*(*) name    [input]
\end{verbatim}
The only place from which to get a valid geometry handle.  {\tt Name}
is used only for identification in printout and subsequent creates.
If the geometry is already opened, a handle to the existing copy is
returned.

\subsubsection{{\tt geom\_destroy}}
\begin{verbatim}
  logical function geom_destroy(geom)
  integer geom          [input]
\end{verbatim}
Delete the incore data structures associated with the geometry and
make the geometry invalid for further use.

\subsubsection{{\tt geom\_check\_handle}}
\begin{verbatim}
  logical function geom_check_handle(geom, msg)
  integer geom          [input]
  character*(*) msg     [input]
\end{verbatim}
If {\tt geom} is not a valid geometry handle then print out {\tt msg}
and return \FALSE.

\subsubsection{{\tt geom\_rtdb\_load}}
\begin{verbatim}
  logical function geom_rtdb_load(rtdb, geom, name)
  integer rtdb          [input]
  integer geom          [input]
  character*(*) name    [input]
\end{verbatim}
Load named geometry from the data base.  One level of translation is
attempted upon the name --- an entry with name {\tt name} is searched
for in the database and if located the value of that entry is used as
the name of the geometry, rather than {\tt name} itself.  {\tt Geom}
must be a valid handle created by \verb+geom_create+.  The same
geometry in the databse may be loaded into distinct in-memory geometry
objects.

\subsubsection{{\tt geom\_rtdb\_store}}
\begin{verbatim}
  logical function geom_rtdb_store(rtdb, geom, name)
  integer rtdb          [input]
  integer geom          [input]
  character*(*) name    [input]
\end{verbatim}  
Store named geometry into the database.  One level of translation is
attempted upon the name.

\subsubsection{{\tt geom\_rtdb\_delete}}
\begin{verbatim}
  logical function geom_rtdb_delete(rtdb, name)
  integer rtdb          [input]
  character*(*) name    [input]
\end{verbatim}
Delete the named geometry from the data base.  One level of
translation is attempted.  Nothing happens to in-core copies of any
geometries.

\subsection{Information about the geometry}

\subsubsection{{\tt geom\_ncent}}
\begin{verbatim}
  logical function geom_ncent(geom, ncent)
  integer geom          [input]
  integer ncent         [output]
\end{verbatim}
Returns in {\tt ncent} the number of centers.

\subsubsection{{\tt geom\_nuc\_charge}}
\begin{verbatim}
  logical function geom_nuc_charge(geom, total_charge)
  integer geom                   [input]
  double precision total_charge  [output]
\end{verbatim}
Return the sum of the nuclear charges.

\subsubsection{{\tt geom\_nuc\_rep\_energy}}
\begin{verbatim}
  logical function geom_nuc_rep_energy(geom, energy)
  integer geom              [input]
  double precision energy   [output]
\end{verbatim}
Return the effective nuclear repulsion energy.  See also
\verb+geom_incude_bqbq()+ (\ref{sec:incbqbq}) and
\verb+geom_set_bqbq()+ (\ref{sec:setbqbq}).

\subsubsection{{\tt geom\_include\_bqbq}}
\label{sec:incbqbq}
\begin{verbatim}
  logical function geom_include_bqbq(geom)
  integer geom          [input]
\end{verbatim}
By default the nuclear repulsion energy returned by
\verb+geom_nuc_rep_energy+ does not include the interactions between
point-charges (i.e., centers which tag begins with \verb+bq+).  This
is so that it is easy for QM-MM programs to generate effective
Hamiltonians based on point charges and avoid double counting of
contributions.  This routine returns \TRUE or \FALSE
if the BQ-BQ contributions are or are not being computed.  The default
(don't include BQ-BQ interactions) thus corresponds to a return value
of \FALSE.

\subsubsection{{\tt geom\_set\_bqbq}}
\label{sec:setbqbq}
\begin{verbatim}
  logical function geom_set_bqbq(geom, value)
  integer geom          [input]
  logical value         [input]
\end{verbatim}
Set the logical variable that determines if BQ-BQ interactions are
included to {\tt value}.

\subsection{Information about centers and coordinates}

\subsubsection{{\tt geom\_cart\_set}}
\begin{verbatim}
  logical function geom_cart_set(geom, ncent, t, c, q)
  integer geom                [input]
  integer ncent               [input]
  character*16 t(ncent)       [input]
  double precision c(3,ncent) [input]
  double precision q(ncent)   [input]
\end{verbatim}
Simple interface for setting tags ({\tt t}), cartesian coords ({\tt
  c}) and charges ({\tt q}) for the geometry.  Atomic units are
currently assumed but might soon be able to specify what units the
interface will use.

\subsubsection{{\tt geom\_cart\_get}}
\begin{verbatim}
  logical function geom_cart_get(geom, ncent, t, c, q)
  integer geom                [input]
  integer ncent               [output]
  character*16 t(ncent)       [output]
  double precision c(3,ncent) [output]
  double precision q(ncent)   [output]
\end{verbatim}
Extracts info from the geometry (opposite of set).  The user is
responsible for determining that the arrays are of sufficient
dimension to hold the output.

\subsubsection{{\tt geom\_cent\_get}}
\begin{verbatim}  
  logical function geom_cent_get(geom, icent, t, c, q)
  integer geom          [input]
  integer icent         [input]
  character*16 t        [output]
  double precision c(3) [output]
  double precision q    [output]
\end{verbatim}
Returns tag/coords/charge about the center {\tt icent}.

\subsubsection{{\tt geom\_cent\_set}}
\begin{verbatim}
  logical function geom_cent_set(geom, icent, t, c, q)
  integer geom          [input]
  integer icent         [input]
  character*16 t        [input]
  double precision c(3) [input]
  double precision q    [input]
\end{verbatim}
Sets values for center {\tt icent} inside the geometry --- opposite of
\verb+geom_cent_get+.

\subsubsection{{\tt geom\_cent\_tag}}
\begin{verbatim}
  logical function geom_cent_tag(geom, icent, tag)
  integer geom          [input]
  integer icent         [input]
  character*16 tag      [output]
\end{verbatim}
Returns just the tag of the center {\tt icent}.

\subsubsection{{\tt geom\_check\_cent}}
\begin{verbatim}
  logical function geom_check_cent(geom, msg, icent)
  integer geom          [input]
  character*(*) msg     [input]
  integer icent         [input]
\end{verbatim}
Return \TRUE if center \verb+icent+ is a valid center,
otherwise return \FALSE and print out the message and other
information. 

\subsection{Support for periodic systems}

\subsubsection{{\tt geom\_systype\_get}}
\begin{verbatim}
  logical function geom_systype_get(geom, itype)
  integer geom          [input]
  integer itype         [input]
\end{verbatim}
Return in {\tt systype} the system type
\begin{itemize}
\item 0 = Molecule
\item 1 = Polymer
\item 2 = Slab
\item 3 = Crystal
\end{itemize}

\subsubsection{{\tt geom\_latvec\_get}}
\begin{verbatim}
  logical function geom_latvec_get(geom, vectors)
  integer geom                [input]
  double precision vectors(3) [output]
\end{verbatim}
For periodic systems, return the lattice constants ({\bf units?}).

\subsubsection{{\tt geom\_latang\_get}}
\begin{verbatim}
  logical function geom_latang_get(geom, angles)
  integer geom                [input]
  double precision angles(3)  [output]
\end{verbatim}
For periodic systems, return the angles defining the lattice.

\subsubsection{{\tt geom\_recipvec\_get}}
\begin{verbatim}
  logical function geom_recipvec_get(geom,rvectors)
  integer geom                [input]
  double precision rvectors(3)[output]
\end{verbatim}
For periodic systems, return the constants of the reciprocal lattice.

\subsubsection{{\tt geom\_recipang\_get}}
\begin{verbatim}
  logical function geom_recipang_get(geom, rangles)
  integer geom                [input]
  double precision rangles(3) [output]
\end{verbatim}
For periodic systems, return the angles defining the reciprocal
lattice ({\bf units?}).

\subsubsection{{\tt geom\_volume\_get}}
\begin{verbatim}
  logical function geom_volume_get(geom,volume)
  integer geom            [input]
  double precision volume [output]
\end{verbatim}
For periodic systems, return the volume of the unit cell ({\bf units?}).

\subsubsection{{\tt geom\_amatrix\_get} and {\tt geom\_amatinv\_get}}
\begin{verbatim}
  logical function geom_amatrix_get(geom,amat)
  integer geom                  [input]
  double precision amat(3,3)    [output]

  logical function geom_amatinv_get(geom,amatinv)
  integer geom                  [input]
  double precision amatinv(3,3) [output]
\end{verbatim}
For periodic systems, return the `A-matrix' or its inverse.  This is
the matrix that transforms fractional coordinates to a Cartesian
system in atomic units (???).  This matrix is the unit matrix for
molecular systems.

\subsection{Printing and miscellaneous routines}

\subsubsection{{\tt geom\_print} and {\tt geom\_print\_xyz}}
\begin{verbatim}
  logical function geom_print(geom)
  integer geom          [input]

  logical function geom_print_xyz(geom, unit)
  integer geom          [input]
  integer unit          [input]
\end{verbatim}
Print out the geometry to standard output.  The {\tt XYZ} form prints
the geometry out to the specified Fortran unit in the XYZ format of 
the molecular viewer {\em Xmol}.

\subsubsection{{\tt geom\_set\_user\_units}}
\begin{verbatim}
  logical function geom_set_user_units(geom, units)
  integer geom          [input]
  character*(*) units   [input]
\end{verbatim}
Set the coordinates that the user expects for input/output.  It
currently understands either `a.u.' or `angstrom'.  Note that
geometries are always internally stored as cartesians in atomic units.

\subsubsection{{\tt geom\_tag\_to\_element}}
\begin{verbatim}
  logical function geom_tag_to_element(tag, symbol, element, atn)
  character*16 tag      [input]
  character*(*) symbol  [output]
  character*(*) element [output]
  integer atn           [output]
\end{verbatim}
Attempt to interpret a tag as the name of an element.  If successful,
return the symbol, full name and atomic number.

\subsubsection{{\tt geom\_charge\_center}}
\begin{verbatim}
  logical function geom_charge_center(geom)
  integer geom          [input]
\end{verbatim}
Adjust the cartesian coordinates so that the nuclear dipole moment is
zero --- i.e., the origin of the coordinate system is at the center of
charge.

\subsubsection{{\tt geom\_num\_core}}
\begin{verbatim}
  logical function geom_num_core(geom, ncore)
  integer geom          [input]
  integer ncore         [output]
\end{verbatim}
Determines the number of core orbitals in a system based on the
constituent atoms and the standard general chemistry ideas of core and
valance.

\subsection{Bugs}

\begin{itemize}
\item It is currently only possible to create a geometry with symmetry
  from the input
\item No internal coordinates
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The basis set object}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


The basis set object and corresponding API was provides access to all
information concerning a basis set from a unique handle.  In this
fashion, multiple distinct basis sets may be manipulated simultanously
on an equal footing.  The internal data structures store only
information for the unique tags in the geometry.

\subsection{Creating, destroying, loading and storing basis sets}

Basis set handles must be created with \verb+bas_create+.  Other
routines load and store basis sets from/to the database.

\subsubsection{{\tt bas\_create}}
\begin{verbatim}
  logical function bas_create(basis, name)
  integer basis       ! [output] returned handle
  character*(*)name   ! [input] name of basis set.  
\end{verbatim}
This is the only source of a valid basis set handle.  The input name
is used for output/debug purposes and is not associated with anything
in the database.  An empty basis set is created (in memory only) and
the handle is returned in {\tt basis}.

\subsubsection{{\tt bas\_destroy}}
\begin{verbatim}
  logical function bas_destroy(basis)
  integer basis ![input] handle to basis set to be destroyed
\end{verbatim}
Frees memory and destroys all information about an active in-memory basis
and the associated mapping arrays.

\subsubsection{{\tt bas\_check\_handle}}
\begin{verbatim}
  logical function bas_check_handle(basis,msg)
  integer basis      ! [input] handle
  character*(*) msg  ! [input] error message
\end{verbatim}
Returns \TRUE\ if {\tt basis} is a valid basis set handle.  Otherwise
it returns \FALSE\ and prints the message and a list of known basis
sets on STDOUT.

\subsubsection{{\tt bas\_rtdb\_load}}
\begin{verbatim}
  logical function bas_rtdb_load(rtdb, geom, basis, name)
  integer rtdb        ! [input] rtdb handle      
  integer geom        ! [input] geometry handle with info loaded
  integer basis       ! [input] basis handle
  character*(*) name  ! [input] name of basis in the rtdb
\end{verbatim}
Routine loads a named basis set from the database (specified with the
handle {\tt rtdb}), and using the geometry information builds the
mapping arrays to contractions or shells, basis functions, and
centers.  One level of translation is attempted upon the name --- an
entry with name {\tt name} is searched for in the database and if
located the value of that entry is used as the name of the basis,
rather than {\tt name} itself.

\subsubsection{{\tt bas\_rtdb\_store}}
\begin{verbatim}
  logical function bas_rtdb_store(rtdb, name, basis)
  integer rtdb              ! [input] handle to database
  character*(*) name        ! [input] name to use when storing
  integer basis             ! [input] handle to basis set
\end{verbatim}
Stores the in-memory basis (referenced by the handle {\tt basis}) into
the specified database (referenced by the handle {\tt rtdb}) using the
specified name.  One level of translation is attempted upon the name
--- an entry with name {\tt name} is searched for in the database and
if located the value of that entry is used as the name of the basis,
rather than {\tt name} itself.  The in-memory basis set is unchanged.

\subsection{Information about the entire basis}

\subsubsection{{\tt bas\_high\_angular}}
\begin{verbatim}
  logical function bas_high_angular(basis,high_angular)
  integer basis         ! [input] basis set handle
  integer high_angular  ! [output] high angular momentum of basis
\end{verbatim}
Returns the highest angular-momentum present in the basis set.

\subsubsection{{\tt bas\_numbf}}
\begin{verbatim}
  logical function bas_numbf(basis,nbf)
  integer basis   ! [input] basis set handle         
  integer nbf     ! [output] number of basis functions
\end{verbatim}
Returns the total number of functions in the basis set.

\subsubsection{{\tt bas\_name}}
\begin{verbatim}
  logical function bas_name(basis,basis_name,trans_name)
  integer       basis    ! [input] basis set handle
  character*(*) basis_name ! [output] symbolic basis name
  character*(*) trans_name ! [output] actual/translated basis name
\end{verbatim}
Returns the name of the basis set.  The ``symbolic'' name used by the
program to load the basis is returned in {\tt name}.  If this name was
used to refer to another basis (i.e., indirection was used) then the
actual name of the basis is returned in {\tt trans} (i.e., the
translated name).  Otherwise {\tt trans} returns the same as name.

\subsubsection{{\tt bas\_numcont}}
\begin{verbatim}
  logical function bas_numcont(basis,numcont)
  integer basis     ! [input] basis set handle
  integer numcont   ! [output] total number of contractions
\end{verbatim}
Returns the total number of mapped general contractions (or shells)
for the given basis set.

\subsubsection{{\tt bas\_nbf\_cn\_max}}
\begin{verbatim}
  logical function bas_nbf_cn_max(basisin,nbf_max)
  integer basisin       ! [input] basis set handle
  integer nbf_max       ! [output] max(nbf in any contraction)
\end{verbatim}
Returns the maximum number of basis functions in any general contraction.

\subsubsection{{\tt bas\_nbf\_ce\_max}}
\begin{verbatim}
  logical function bas_nbf_ce_max(basisin,nbf_max)
  integer basisin       ! [input] basis set handle
  integer nbf_max       ! [output] max(nbf on any center)
\end{verbatim}
Returns the maximum number of basis functions on any single center.

\subsection{Mapping between centers, shells/contractions and functions}

\subsubsection{{\tt bas\_cn2ce}}
\begin{verbatim}
  logical function bas_cn2ce(basis,cont,center)
  integer basis     ! [input] basis set handle
  integer cont      ! [input] mapped contraction index
  integer center    ! [output] center index
\end{verbatim}
Returns the center for a given mapped (as opposed to unique)
contraction.

\subsubsection{{\tt bas\_cn2bfr}}
\begin{verbatim}
  logical function bas_cn2bfr(basis,cont,ifirst,ilast)
  integer basis     ! [input] basis set handle
  integer cont      ! [input] mapped contraction index
  integer ifirst    ! [output] first basis function
  integer ilast     ! [output] last basis function     
\end{verbatim}
Returns the first basis function index of a mapped contraction in
{\tt ifirst} and the last basis function index in {\tt ilast}.

\subsubsection{{\tt bas\_ce2bfr}}
\begin{verbatim}
  logical function bas_ce2bfr(basis, icent, ibflo, ibfhi)
  integer basis             ! [input] handle
  integer icent             ! [input] no. of center
  integer ibflo, ibfhi      ! [output] range of functions on center
\end{verbatim}
Returns the range of basis functions on a given center.

\subsubsection{{\tt bas\_ce2cnr}}
\begin{verbatim}
  logical function bas_ce2cnr(basis,center,ifirst,ilast)
  integer basis    ! [input] basis set handle         
  integer center   ! [input] center index 
  integer ifirst   ! [output] first mapped contraction
  integer ilast    ! [output] last mapped contraction
\end{verbatim}
Returns the range of mapped contractions on a given center.

\subsubsection{{\tt bas\_bf2ce}}
\begin{verbatim}
  logical function bas_bf2ce(basis,testbf,center)
  integer basis   ! [input] basis set handle         
  integer testbf  ! [input] basis function index
  integer center  ! [output] center index
\end{verbatim}
Returns the center on which a basis function resides.

\subsubsection{{\tt bas\_bf2cn}}
\begin{verbatim}
  logical function bas_bf2cn(basis,testbf,cont)
  integer basis   ! [input] basis set handle         
  integer testbf  ! [input] basis function index
  integer cont    ! [output] mapped contraction index
\end{verbatim}
Returns the mapped contraction index that contains the given basis
function index.

\subsection{Printing}

\subsubsection{{\tt bas\_print}}
\begin{verbatim}
  logical function bas_print(basis)
  integer basis   ! [input] basis handle
\end{verbatim}
Prints in the information about the basis set on unique centers.

\subsubsection{{\tt bas\_print\_all}}
\begin{verbatim}
  logical function bas_print_all()
\end{verbatim}
Debugging routine.  Prints (using \verb+bas_print+) information about
all active basis sets.

\subsubsection{{\tt gbs\_map\_print}}
\begin{verbatim}
  logical function gbs_map_print(basis)
  integer basis    ! [input] basis set handle
\end{verbatim}
Prints detailed information about the mapping of the unique basis set
information to the centers (using the geometry information).  Mostly
useful only for debugging.


\subsection{Detailed contraction information, exponents, coefficients,
  etc..} 

\subsubsection{{\tt bas\_continfo}}
\begin{verbatim}
  logical function bas_continfo(basis,icont,
 &       type,nprimo,ngeno,sphcart)
  integer basis             ! [input] basis handle
  integer icont             ! [input] contraction index
  integer type              ! [output] type (sp/s/p/d/..)
  integer nprimo            ! [output] no. of primitives
  integer ngeno             ! [output] no. of contractions
  integer sphcart           ! [output] 0/1 for cartesian/spherical
\end{verbatim}
Returns information about the specified general contraction or shell.
Type is encoded so that the sequence {\em spd/sp/s/p/d/f\ldots} map
into -2/-1/0/1/2/3/\ldots.  The number of primitives is equivalent to
the number of exponents.  The number of contractions is the number of
radial functions to which the primitives are contracted, or equivalently,
the number of sets of coefficients.

\subsubsection{{\tt bas\_get\_exponent} and {\tt bas\_set\_exponent}}
\begin{verbatim}
  logical function bas_get_exponent(basis,icont,exp) integer basis !
  [input] basis set handle integer icont ! [input] mapped contraction
  index double precision exp(*) ! [output] exponents

  logical function bas_set_exponent(basis,icont,exp,nexp) integer
  basis ! [input] basis set handle integer icont ! [input] mapped
  contraction index integer nexp ! [input] number of new exponents
  double precision exp(nexp) ! [input] "new" exponents for contraction
\end{verbatim}
Get/set the exponents associated with a contraction.  When setting the
exponents two points must be noted:
\begin{enumerate}
\item the number of new exponents must {\em exactly} match the number
  of old exponents, and
\item since internally exponents are only stored once for atoms of the
  same type, changes effect all atoms of the same type.
\end{enumerate}

\subsubsection{{\tt bas\_get\_coeff} and {\tt bas\_set\_coeff}}
\begin{verbatim}
  logical function bas_get_coeff(basis,icont,coeff)
  integer basis              ! [input] basis set handle
  integer icont              ! [input] mapped contraction index
  double precision coeff(*)  ! [output] mapped contraction coeffs.

  logical function bas_set_coeff(basis,icont,coeff,ncoeff)
  integer basis                   ! [input] basis set handle                   
  integer icont                   ! [input] mapped contraction index           
  integer ncoeff                  ! [input] number of coeffs.
  double precision coeff(ncoeff)  ! [input] "new" coeffs. 
\end{verbatim}
Get/set the contraction coefficients associated with a generally
contracted function.  The coefficients are stored as if the array was
declared as {\tt coeff(nprim,ngen)} where {\tt nprim} is the number of
primitive and {\tt ngen} is the number of sets of coefficients.  When
setting the coefficients two points must be noted:
\begin{enumerate}
\item the number of new coefficients must {\em exactly} match the
  number of old coefficients (i.e., {\tt ncoeff} = {\tt nprim*ngen}, and
\item since internally coefficients are only stored once for atoms of the
  same type, changes effect all atoms of the same type.
\end{enumerate}

\subsection{Other --- unique contraction information and adding
centers}

Routines exist to do all of this stuff, however, it is not anticipated
that this functionality is necessary outside of existing input
routines.  Counterexamples would be automatic creation of fitting
basis sets or automatic optimization of an existing basis set.
Rather than confuse most users by documenting this ``private
interface'', anyone seeking additional functionality should contact
Rick or Robert --- the interface you want is probably there.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Symmetry}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  The symmetry stuff is intended to work for both molecular and
periodic systems, so bits and pieces will change over time as the
periodic code starts to function.

  All of the the symmetry information is buried in the geometry
object, so unless you are messing with the orbitals or basis only a
geometry handle is necessary to get all of the information.

{\em The documentation is still being written, but this list of
  routines should still be useful.}

\subsection{Basic functionality}

\subsubsection{{\tt sym\_group\_name}}
\begin{verbatim}
  subroutine sym_group_name(geom, name)
  integer geom              ! [input]
  character*(*) name        ! [output] returns the group name
\end{verbatim}

\subsubsection{{\tt sym\_number\_ops}}
\begin{verbatim}
  integer function sym_number_ops(geom)
  integer geom              ! [input]
\end{verbatim}
Returns the number of operations in the group {\em excluding} the
identity.  Thus, $C_1$ is thought to contain zero operators and
$C_{2v}$ three operators.

\subsubsection{{\tt sym\_center\_map}}
\begin{verbatim}
  integer function sym_center_map(geom, cent, op)
  integer geom             ! [input]
  integer cent             ! [input] Geometrical center
  integer op               ! [input] Operator
\end{verbatim}
Returns the index of the center that the input center
(\verb+cent+) maps into under the action of the operator
(numbered 1, \ldots, \verb+sym_number_ops(geom)+).

\subsubsection{{\tt sym\_inv\_op}}
\label{sec:syminvop}
\begin{verbatim}
  subroutine sym_inv_op(geom, op, opinv)
  integer geom             ! [input]
  integer op               ! [input] Operator number
  integer opinv            ! [output] Inverse operator
\end{verbatim}
Returns in \verb+opinv+ the index of the operator that is
the inverse to the operator \verb+op+.

\subsubsection{{\tt sym\_apply\_op}}
\begin{verbatim}
  subroutine sym_apply_op(geom, op, r, rnew)
  integer geom
  integer op
  double precision r(3)
  double precision rnew(3)
\end{verbatim}
Apply the operator \verb+op+ to the 3-vector \verb+r+ returning the
result in \verb+rnew+.  {\em Note that this routine acts on
  coordinates natural to the system --- Cartesian for molecules and
  fractional for periodic systems.}

\subsubsection{{\tt sym\_apply\_cart\_op.F}}
\begin{verbatim}
  subroutine sym_apply_cart_op(geom, op, r, rnew)
  integer geom
  integer op
  double precision r(3)
  double precision rnew(3)
\end{verbatim}
Apply the operator \verb+op+ to the Cartesian 3-vector \verb+r+
returning the result in \verb+rnew+.  {\em Note that this routine acts
  only on Cartesian coordinates.}

\subsubsection{{\tt sym\_get\_cart\_op}}
\begin{verbatim}
  subroutine sym_get_cart_op(geom, op, matrix)
  integer geom          ! [input]
  integer op            ! [input] Operator
  double precision matrix(3,4) ! [output] Returns cartesian operator
\end{verbatim}
Return the matrix representation of the operator that acts on
Cartesian coordinates.  The first three columns correspond to the
point group operator and the final column is the translation.

\begin{verbatim}
    OP * r(1:3) = r'(1:3) = matrix(1:3,1:3)*r(1:3) + matrix(1:3,4)
\end{verbatim}

\subsubsection{{\tt sym\_ops\_get}}
\begin{verbatim}
  subroutine sym_ops_get(geom, numops, symops)
  integer geom      ! [input]
  integer numops    ! [input] Leading dim. of symops
  double precision symops(numops*3,4) ! [input] Returns operators
\end{verbatim}
Returns in \verb+symops+ the first \verb+numops+ operators.  It's 
probably not necessary to use this routine.

\subsubsection{{\tt sym\_op\_mult\_table}}
\begin{verbatim}
  subroutine sym_op_mult_table(geom, table, ld)
  integer geom              ! [input]
  integer ld
  integer table(ld,*)
c
c !! THIS ROUTINE HAS NOT BEEN COMPILED OR TESTED !!
c
\end{verbatim}
Return in \verb+table+ the multiplication table for the operators
excluding the identity --- inside the table the identity is labelled
as zero.

\subsection{Geometries and gradients}

These routines actually do exactly the same thing internally, but the
interface differs according to their natural usage.

\subsubsection{{\tt sym\_geom\_project}}
\begin{verbatim}
  subroutine sym_geom_project(geom, tol)
  integer geom             ! [input]
  double precision tol     ! [input]
\end{verbatim}
Apply a projection operator to the geometry so that it posesses the
symmetry of the group to machine precision.  An atom and the image of
that atom under the operations of the group are considered to be
identical {\em iff} they are less than \verb+tol+ distant from each
other.  If the two centers that should be symmetry equivalent differ
by more than \verb+tol+ then a fatal error results.  This operation
should be idempotent.

\subsubsection{{\tt sym\_grad\_symmetrize}}
\begin{verbatim}
  subroutine sym_grad_symmetrize(geom, grad)
  integer geom                ! [input]
  double precision grad(3,*)  ! [input/output]
\end{verbatim}
Apply a projection operator to the gradient so that it posesses the
symmetry of the group to machine precision.  This is appropriate for
projecting out the totally symmetric component of a gradient
constructed from a skeleton integral list.  This operation should be
idempotent. 

\subsection{Character tables}

In order to make use of the character table you need to determine the
class of each operator.  Note that the identity is the only operator
in the first class.

\subsubsection{{\tt sym\_char\_table}}
\begin{verbatim}
  logical function sym_char_table(zname, nop, nir, class_dim,
 &     zir, zclass, chars)
  character*8 zname         ! [input]
  integer nop               ! [output] Returns no. ops (with identity)
  integer nir               ! [output] Returns no. irreducible reps.
  integer class_dim(*)      ! [output] Returns dim. of each class
  character*8 zir(*)        ! [output] Returns name of each irrep
  character*8 zclass(*)     ! [output] Returns name of each class
  double precision chars(*) ! [output] Returns the character table
\end{verbatim}
Given the name of the group, this routine returns the
total number of operators (\verb+nop+) including the identity, the
number of irreducible representations (\verb+nir+), the name of each
irreducible representation (\verb+zir(i)+, =verb+i=1,...,nir+), the
dimension and name of each class (\verb+class_dim(i)+,
\verb+zclass(i)+, \verb+i=1,...,nir+), and the character table.  
Returns \TRUE\ if group character table was available, \FALSE\ 
otherwise.

The character of class \verb+C+ in irreducible representation \verb+R+
is stored in \verb+char(C,R)+ if \verb+char+ is dimensioned as
\begin{verbatim}
   double precision char(nir,nir)
\end{verbatim}
The maximum number of irreducible representations in any point group
is 20 and the maximum number of operators is 120.  Thus, you can just
paste these declarations into your code to call this routine
\begin{verbatim}
  integer maxop, maxireps     
  parameter (maxop = 120, maxireps=20)
  integer nop, nir,  nop_table, class_dim(maxireps)
  character*8 zir(maxireps), zclass(maxireps)
  double precision chars(maxireps*maxireps)

  if (.not. sym_char_table(zname, nop, nir, class_dim,
 $     zir, zclass, chars)) call errquit(' ... ',0)
\end{verbatim}

All is simple except for complex conjugate pairs of irreducible
representations that are stored with one having the real pieces of the
characters and the other the imaginary.  This leads to the second
having a zero character for the identify, however a valid projection
operator can still be constructed (look in \verb+sym_movecs_adapt()+).

\subsubsection{{\tt sym\_op\_classify}}
\begin{verbatim}
  subroutine sym_op_classify(geom, op_class_index)
  integer geom              ! [input]
  integer op_class_index(*) ! [output] Class number of each op
\end{verbatim}
Return an array that has for each operator the number of the class to
which it belongs.  This index makes the connection between the
operator and the character table.  The operators are numbered,
exluding the identity, from 1 to \verb+sym_number_ops()+.

\subsection{Atomic/molecular orbitals}

\subsubsection{{\tt sym\_bas\_irreps}}
\begin{verbatim}
  subroutine sym_bas_irreps(basis, oprint, nbf_per_ir)
  integer basis             ! [input] basis handle
  logical oprint            ! [input] if true then print
  integer nbf_per_ir(*)     ! [output] 
\end{verbatim}
Return in \verb+nbf_per_ir+ the number of functions per irreducible
representation that are present in the specified basis set.  The
maximim number of irreducible represenations in any point group is 20.

\subsubsection{{\tt sym\_movecs\_adapt}}
\begin{verbatim}
  subroutine sym_movecs_adapt(basis, thresh, g_vecs, irs, nmixed)
  integer basis             ! [input]
  double precision thresh   ! [input]
  integer g_vecs            ! [input]
  integer irs(*)            ! [output]
  integer nmixed            ! [output]
\end{verbatim}
Symmetry adapt the molecular orbitals in the GA \verb+ga_vecs+,
returning in \verb+irs(i)+ the number of the irreducible
representation of the i'th molecular orbital.  In \verb+nmixed+ is
returned the number of input molecular orbitals that were symmetry
contaminated greater than \verb+thresh+.  An MO is deemed contaminated
if it contains two or more irreps. with coefficients greater than
\verb+thresh+.

{\em Note:} If the input MOs are nearly linearly dependent then the
output MOs may be exactly linearly dependent since if the component
distinguishing two vectors is not the dominant symmetry component it
will be projected out.  If in doubt call \verb+ga_orthog()+ before
calling this routine.

{\em Note:} If mixing was present it may be necessary to call
\verb+ga_orthog()+ to reorthogonalize the output vectors.

\subsubsection{{\tt sym\_movecs\_apply\_op}}
\begin{verbatim}
  subroutine sym_movecs_apply_op(basis, op, v, t)
  integer basis             ! [input]
  integer  op               ! [input]
  double precision v(*)     ! [input]
  double precision t(*)     ! [output]
\end{verbatim}
Apply the group operation \verb+op+ to the vector of basis function
coefficients (i.e., a MO vector) in \verb+v(*)+, returning the result
in \verb+t(*)+.

\subsubsection{{\tt sym\_bas\_op}}
\begin{verbatim}
  subroutine sym_bas_op(geom, op, r, maxf, ang_max)
  integer geom              ! [input]
  integer op                ! [input] Desired operator
  integer maxf              ! [input] Leading dimension of r
  integer ang_max           ! [input] Max. ang. momentum of shell
  double precision r(1:maxf,1:maxf,0:ang_max) ! [output] The operator
\end{verbatim}
Return the transformation matrices for basis functions up to the
specified maximum angular momentum under the specified group
operation.

{\em Note} that the identity operation is not included.

{\em Note} that only cartesian shells are supported, but sphericals
will be integrated when available.

Let \verb+X(I,L)+ be the I'th function in a shell with angular
momentum L.  The application of a symmetry operator will
map shell X into an equivalent shell on a possibly different
center and will also mix up the components of the shell
according to
\begin{verbatim}
    R op X(I,L) = sum(J) X(J,L)*R(J,I,L)
\end{verbatim}

In dealing with Cartesian functions it is necessary to pay careful
attention to if you are using the inverse or transpose of an operator
(see Dupuis and King, IJQC 11, 613-625, 1977).  To apply the inverse
operator simply use both the center mapping and transformation
matrices of the inverse operator.  However, since the representation
matrices are {\em not} unitary in the Cartesian basis then to generate
the effect the transposed matrices of an operator you must
\begin{itemize}
\item map (atomic or basis function) centers according to the mapping
  provided for the inverse operation (see section \ref{sec:syminvop})
\item apply the transpose of coefficients (i.e., use \verb+R(I,J,L)+
  instead of \verb+R(J,I,L)+ in the above transformation).
\end{itemize}

For examples of how this routine is used in practice look in
\verb+symmetry/sym_mo_adapt.F+ or \verb+symmetry/sym_sym.F+.

\subsection{`Skeleton' integral lists}

Note that the consituency number (point group component only) for
shells is exactly the same as that for that atoms on which they reside.

\subsubsection{{\tt sym\_atom\_pair}}
\begin{verbatim}
  logical function sym_atom_pair(geom, iat, jat, q2)
  integer geom              ! [input] Geometry handle
  integer iat, jat          ! [input] Atom indices
  double precision q2       ! [output] Constituency number
\end{verbmatim}
Return \TRUE\ if \verb+(iat,jat)+ is the lexically highest pair of
symmetry equivalent atoms. If \TRUE\ also return the constituency
factor \verb+q2+ (which is the number of symmetry equivalent pairs).

This routine uses the exchange symmetry \verb+iat <-> jat+ but does
not incorporate any factors into \verb+q2+ to account for this (i.e.,
\verb+q2+ includes point group symmetry only).

\subsubsection{{\tt sym\_atom\_quartet} and {\tt sym\_atom\_gen\_quartet}}
\begin{verbatim}
  logical function sym_atom_quartet(geom, iat, jat, kat, lat, q4)
  integer geom               ! [input] Geometry handle
  integer iat, jat, kat, lat ! [input] Atom indices
  double precision q4        ! [output] Constituency number
\end{verbatim}
Return \TRUE\ if \verb+(iat,jat,kat,lat)+ is the lexically highest
quartet of symmetry equivalent atoms. If \TRUE\ also return the
constituency factor \verb+q4+ (which is the number of symmetry
equivalent quartets).

This routine uses the standard three index exchange symmetries
\verb+(iat<->jat)+ \verb+<->+ \verb+(kat<->lat)+ but does not
incorporate any additional factors into \verb+q4+ (i.e., \verb+q4+
reflects only the point group symmetry).  Look in the \verb+ddscf/+
directory for examples of its use.

\begin{verbatim}
  logical function sym_atom_gen_quartet(geom, iat, jat, kat, lat, q4)
\end{verbatim}
This routine differs from \verb+sym_atom_quartet+ only in that it
uses just two index exchage symmetries \verb+(iat<->jat)+ and
\verb+(kat<->lat)+.  Look in the \verb+moints/+ directory for examples
of its use.

\subsubsection{{\tt sym\_shell\_pair}}
\begin{verbatim}
  logical function sym_shell_pair(basis, ishell, jshell, q2)
  integer basis             ! Basis set handle [input]
  integer ishell, jshell    ! Shell indices [input]
  double precision q2       ! Constituency number [output]
\end{verbatim}
Return |TRUE\ if \verb+(ishell,jshell)+ is the lexically highest pair
of symmetry equivalent shells. If \TRUE\, also return the constituency
factor \verb+q2+ (which is equal to the number of symmetry equivalent
pairs).

This routine uses the exchange symmetry \verb+ishell <-> jshell+ and
{\em incorporates a factor of two into \verb+q2+ to account for this}.
However, this factor of two may be removed at some point in order to
make the shell based routines exactly consistent with the atom based
code.

\subsubsection{{\tt sym\_shell\_quartet}}
\begin{verbatim}
  logical function sym_shell_quartet(basis,
 &     ishell, jshell, kshell, lshell, q4)
  integer basis             ! Basis set handle [input]
  integer ishell, jshell    ! Shell indices [input]
  integer kshell, lshell    ! Shell indices [input]
  double precision q4       ! Constituency number [output]
\end{verbatim}
Return \TRUE\ if \verb+(ishell,jshell,kshell,lshell)+ is the lexically highest
quartet of symmetry equivalent shells. If \TRUE\ also return the
constituency factor \verb+q4+ (which is the number of symmetry
equivalent quartets).

This routine uses the standard three index exchange symmetries
\verb+(ishell<->jshell)+ \verb+<->+ \verb+(kshell<->lshell)+ but does
not incorporate any additional factors into \verb+q4+ (i.e., \verb+q4+
reflects only the point group symmetry).  Look in the \verb+ddscf/+
directory for examples of its use.

\subsubsection{{\tt sym\_symmetrize}}
\begin{verbatim}
  subroutine sym_symmetrize(geom, basis, odensity, g_a)
  integer geom       ! [input] Geometry handle
  integer basis      ! [input] Basis handle
  integer g_a        ! [input] Global array to be symmetrized
  logical odensity   ! [input] true=density, false=hamiltonian
\end{verbatim}
Symmetrize a skeleton AO matrix (in global array with handle
\verb+g_a+) in the given basis set.  This is nothing more than
applying the projection operator for the totally symmetric
representation.
\begin{verbatim}
   B = (1/2h) * sum(R) [RT * (A + AT) * R]
\end{verbatim}
where \verb+R+ runs over all operators in the group (including
identity) and \verb+h+ is the order of the group.

Note that density matrices tranform according to slightly different
rules to Hamiltonian matrices if components of a shell (e.g.,
cartesian d's) are not orthonormal.  (see Dupuis and King, IJQC 11,
613-625, 1977).  Hence, speficy \verb+odensity+ as \TRUE\ for
density-like matrices and \FALSE\ for all other totally symmetric
Hamiltonian-like operators.

\subsection{Printing}

\subsubsection{{\tt sym\_print\_all}}
\begin{verbatim}
  subroutine sym_print_all(geom, oinfo, ouniq, omap, oops, ochar)
  integer geom              ! [input]
  logical oinfo             ! [input] print information
  logical ouniq             ! [input] print list of unique atoms
  logical omap              ! [input] print mapping of atoms under ops
  logical oops              ! [input] print operator matrices
  logical ochar             ! [input] print character table
\end{verbatim}
Print out all symmetry related information inside the geometry object
\begin{description}
\item{oinfo} prints the name and order of the group
\item{ouniq} prints the list of symmetry unique atoms
\item{omap} prints the transformation of atoms under group operations
\item{oops} prints the matrix representation of operators including
  class information
\item{ochar} prints the character table
\end{description}

\subsubsection{{\tt sym\_print\_char\_table}}
\begin{verbatim}
  subroutine sym_print_char_table(geom)
  integer geom              ! [input]
\end{verbatim}
Print the character table for the group to Fortran unit 6.


\subsubsection{{\tt sym\_print\_ops}}
\begin{verbatim}
  subroutine sym_print_ops(geom)
  integer geom              ! [input]
\end{verbatim}
Called by \verb+sym_print_all+ to print the operators.  You can call
it too if you like.

\subsection{Internal stuff that might be useful}

\subsubsection{{\tt sym\_op\_type}}

\subsubsection{{\tt sym\_op\_class\_name}}

\subsection{Miscellaneous}

\subsubsection{{\tt cross\_product}}

\subsubsection{{\tt deter3}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Context}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Context is dead.  All context routines will be removed in the near
future.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Utility routines}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The NWChem {\tt util} directory is a dumping ground for all sorts of useful
things, some of which have been described elsewhere.  Here is the rest.

\subsection{Printing utilities}

\subsubsection{{\tt util\_print\_centered}}
\begin{verbatim}
  subroutine util_print_centered(unit, string, center, ounder)
  integer unit             [input]
  character*(*) string     [input]
  integer center           [input]
  logical ounder           [input]
\end{verbatim}
Write the string to speficied Fortran unit centered about the given
column.  If {\tt ounder} is \TRUE then the string is underlined.

\subsubsection{{\tt banner}}
\begin{verbatim}
  subroutine banner(unit, string, char, top, bot, sides)
  integer unit             [input]
  character*(*) string     [input]
  character*(1) char       [input]
  logical top, bot, sides  [input]
\end{verbatim}
Write the string to spcified Fortran unit flush against the left
margin optionaly enlcosing the top/bottom/sides with a box constructed
from the given character.  At some point this routine should be renamed
\verb+util_banner+. 

\subsubsection{{\tt output}}
\begin{verbatim}
  subroutine output (z, rowlow, rowhi, collow, colhi,
                     rowdim, coldim, nctl)
  double precision z(rowdim, coldim)
  integer  rowlow, rowhi, collow, colhi, rowdim, coldim, nctl
\end{verbatim}
{\tt Output} is a classic routine that prints non-zero rows of a
double precision matrix in formatted form with numbered rows
and columns.  The arcane input is as follows;
\begin{itemize}
\item  {\tt z} --- matrix to be printed
\item  {\tt rowlow} --- row number at which output is to begin
\item  {\tt rowhi} --- row number at which output is to end
\item  {\tt collow} --- column number at which output is to begin
\item  {\tt colhi} --- column number at which output is to end
\item  {\tt rowdim} --- number of rows in the matrix
\item  {\tt coldim} --- number of columns in the matrix
\item {\tt nctl} --- carriage control flag; 1 for single space 2 for
  double space 3 for triple space --- only 1 looks any good.
\end{itemize}
Two examples might help.  To print {\tt z(3:6,8:12)}
\begin{verbatim}
  double precision z(n,m)
  call output(z, 3, 6, 8, 12, n, m, 1)
\end{verbatim}
To print {\tt x(3:12)}
\begin{verbatim}
  double precision x(n)
  call output(x, 3, 12, 1, 1, n, 1, 1)
\end{verbatim}

\subsection{Error routines}

\subsubsection{{\tt errquit}}
\label{errquit}
\begin{verbatim}
  subroutine errquit(string, status)
  character*(*) string
  integer status
\end{verbatim}
All fatal errors should result in a call to this routine, which prints
out the string and status value to both standard error and standard
output and attempts to kill all parallel processes and to tidy any
allocated system resources (e.g., system V shared memory).

\subsection{Parallel communication}

\subsubsection{{\tt util\_char\_ga\_brdcst}}
\begin{verbatim}
  subroutine util_char_ga_brdcst(type, string, originator)
  integer type            [input]
  character*(*) string    [input/output]
  integer originator      [input]
\end{verbatim}
The standard broadcast routine {\tt ga\_brdcst} does not work portably
with Fortran character strings for which this routine should be used
instead.  The string is broadcast from process \verb+originator+ to all other
processes.  Type is the standard message type or tag. All processes
should execute the same call and there is an implied weak
synchronization (i.e., no process can complete this statement until at
least process \verb+originator+ has reached it).

\subsubsection{{\tt fcsnd} and {\tt fcrcv}}
\begin{verbatim}
  subroutine fcsnd(type, string, node, sync)
  subroutine fcrcv(type, string, slen, nodeselect, nodefrom, sync)
\end{verbatim}
Similarly, the basic point-to-point message-passing routines do not
work portably with Fortran character strings.  Here are routines that
work only with character strings.  Refer to the standard TCGMSG
documentation for details on the other arguments.

\subsection{Naming files}

The length of a file name can be large and also system depenedent.
The parameter \verb+NW_MAX_PATH_LEN+ is defined in \verb+util.fh+ to
enable a portable definition.  Use it as follows
\begin{verbatim}
#include "util.fh"
      character*(nw_max_path_len) filename
\end{verbatim}

For easy management by a use of NWChem, and so that multiple jobs can
run without interaction in the same directory tree, all files should
by default have a common prefix (speficied on the {\tt START} or {\tt
  RESTART} directive).  In addition, files need to be routed to the
correct directory (scratch or permanent) and parallel files need the
process number appended to the name.  Routines (should) exist to do
all of these things individually, but one master routine does it all
for you --- wow!

\subsubsection{{\tt util\_file\_name}}

\begin{verbatim}
  subroutine util_file_name(stub, oscratch, oparallel, name)
  character*(*) stub      ! [input] stub name for file
  logical oscratch        ! [input] T=scratch, F=permanent
  logical oparallel       ! [input] T=append .<nodeid>
  character*(*) name      ! [output] full filename
\end{verbatim}

This routine prepends the common file prefix (speficied on the {\tt
  START} or {\tt RESTART} directive) and directory (scratch or
permanent) and appends the process number for parallel files. For
example
\begin{verbatim}
   call util_file_name('movecs', .false., .false., name)
\end{verbatim}
might result in \verb+name+ being set to
\verb+/msrc/home/d3g681/c60.movecs+ (i.e., having the name of the
permanent directory and the file prefix prepended onto the stub).

Another example,
\begin{verbatim}
   call util_file_name('khalf', .true., .true., name)
\end{verbatim}
might yield \verb+/scratch/h2o.khalf.99+ (i.e., having the name
of the scratch directory and the file prefix prepended and the process
number appended).

\subsubsection{{\tt util\_file\_prefix}}
\begin{verbatim}
  subroutine util_file_prefix(name, fullname)
  character*(*) name         [input]
  character*(*) fullname     [output]
\end{verbatim}
{\em This routine is superceded for most purposes by}\ 
\verb+util_file_name()+.  

By default all filenames should be prefixed
with the \verb+file_prefix+ which is the argument presented to the
\verb+start+ or \verb+restart+ directive in the input.  This is most
simply accomplished by calling this routine which returns in
\verb+fullname+ the value of \verb+file_prefix+ followed (with no
intervening characters) by the contents of \verb+name+.

\subsubsection{{\tt util\_pname}}
\begin{verbatim}
  subroutine util_pname(name, pname)
  character*(*) name         [input]
  character*(*) pname        [output]
\end{verbatim}
{\em This routine is superceded for most purposes by}\ 
\verb+util_file_name()+.  

Construct a unique parallel name by appending the process number after
the stub name. E.g., \verb+fred.0001+, \verb+fred.0002+, \ldots. The
number of leading zeroes are adjusted so that there are none in front
of the highest numbered processor.  This is useful for generating
names for files, but is probably superseded by the exclusive access
files in CHEMIO.

\subsection{Sequential Fortran files}

\subsubsection{{\tt util\_flush}}
\begin{verbatim}
  subroutine util_flush(unit)
  integer unit        [input]
\end{verbatim}
If possible, flush the Fortran output buffers associated with the
specified unit.  Note that this is generally required in order for
output to be visible during the course of a calculation and thus
should be called after most write operations to standard output.
Also, on some machines it is a fatal error to flush a unit on which no
output has been performed thus care must be taken to ensure that
writes and flushes are paired --- e.g., it is wrong to have all
processes flush unit six when only process zero has written output.

\subsubsection{{\tt sread} and {swrite}}
\begin{verbatim}
  subroutine sread(unit, a, n)
  integer unit            [input]
  double precision a(n)   [output]
  integer n               [input]

  subroutine swrite(unit, a, n)
  integer unit            [input]
  double precision a(n)   [input]
  integer n               [input]
\end{verbatim}
A blast from the past and hopefully only temporarily present here.
May also be renamed by prefixing with \verb+util_+.  Read/write an
array of {\tt double} {\tt precision} words from the given Fortran
unit (variable record length, binary file).  These routines are
valuable to avoid inefficient implied {\tt DO} loops and also to
circumvent system limitations on record lengths (e.g., some Cray
systems).  The I/O operations are internally chopped into 0.25~Mbyte
chunks.

\subsection{Parallel file operations}

\subsubsection{{\tt begin\_seq\_output}, {\tt write\_seq}, and {\tt end\_seq\_output}}
\begin{verbatim}
  subroutine begin_seq_output

  subroutine write_seq(unit, text)
  integer unit        [input]
  character*(*) text  [input]

  subroutine end_seq_output
\end{verbatim}
These routines support sequential (i.e., ordered) formatted output
from all parallel processes.  A call to \verb+begin_seq_output+
indicates the start of a section of sequentialized output.  This can
be followed by any number of calls to \verb+write_seq+, which {\em
  must} be followed by calling \verb+end_seq_output+.  All output will
be sent to node 0 and written there in order of increasing node
number.

{\em All nodes must participate in all calls of a sequential output section}.

Because we have to declare a fixed length string, it is possible for
some transmissions to be truncated.  In practice, however, we choose
something rather longer than typical line lengths and it should not be
a serious problem.

Observe that the specified unit is the Fortran unit on node zero, not
that of the invoking node!

\subsection{Data packing and unpacking}
\begin{verbatim}
  subroutine util_pack_16(nunpacked, packed, unpacked)
  integer nunpacked                     [input]
  integer packed(*)                     [output]
  integer unpacked(nunpacked)           [input]

  subroutine util_unpack_16(nunpacked, packed, unpacked)
  integer nunpacked                     [input]
  integer packed(*)                     [input]
  integer unpacked(nunpacked)           [output]

  subroutine util_pack_8(nunpacked, packed, unpacked)
  integer nunpacked                     [input]
  integer packed(*)                     [output]
  integer unpacked(nunpacked)           [input]

  subroutine util_unpack_8(nunpacked, packed, unpacked)
  integer nunpacked                     [input]
  integer packed(*)                     [input]
  integer unpacked(nunpacked)           [output]
\end{verbatim}
These routines pack/unpack unsigned eight bit (0--255) or sixteen bit
(0--65535) integers to/from standard Fortran integers.  The number of
unpacked numbers {\em must} be a multiple of the number of values that
fit into a single Fortran integer.  On 32 bit machines this is four
eight-bit values and two sixteen-bit values.  On 64 bit machines these
numbers are eight and four respectively.  The number of values that
can be packed per integer can be computed in a machine
independent fashion using MA
\begin{verbatim}
  npacked_per_int = ma_sizeof(mt_int, 1, mt_byte) / 
                                        n_bytes_per_value
\end{verbatim}
under the assumption that the word length is an exact multiple of the
value length.

\subsection{Checksums}

Checksums are useful for rapid comparison and validation of data, such
as digital signatures for verification of important messages, or, more
relevant to us, to determine if input and disk resident restart data
are still consistent.  The checksum routines provided here are
wrappers around the RSA implementation of the RSA Data Security, Inc.
MD5 Message-Digest Algorithm.  It is the reference implementation for
internet RFC 1321, The MD5 Message-Digest Algorithm, and as such has
been extensively tested and there are no restrictions placed upon its
distribution or export.  License is granted by RSA to make and use
derivative works provided that such works are identified as "derived
from the RSA Data Security, Inc. MD5 Message-Digest Algorithm" in all
material mentioning or referencing the derived work.  Consider this
done.  The unmodified network posting is included in md5.txt for
reference.

\begin{quote}
MD5 is probably the strongest checksum algorithm most people will need
for common use.  It is conjectured that the difficulty of coming up
with two messages having the same message digest is on the order of
$2^64$ operations, and that the difficulty of coming up with any
message having a given message digest is on the order of $2^128$
operations.
\end{quote}

The checksums are returned (through the NWChem interface) as character
strings containing a 32 character hexadecimal representation of the
128 bit binary checksum.  This form loses no information, may be
readily compared with single statements of standard C/F77, is easily
printed, and does not suffer from byte ordering problems.  The
checksum depends on both the value and order of data, and thus
differing numerical representations, floating-point rounding
behaviour, and byte ordering, make the checksum of all but simple text
data usually machine dependent unless great care is taken when moving
data between machines.  The Fortran test program merely tests the
Fortran interface.  For a more definitive test of MD5 make
\verb+mddriver+ and execute it with the \verb+-x+ option, comparing
output with that in \verb+md5.txt+.

\subsubsection{Checksum C and Fortran interface}

C routines should include \verb+checksum.h+ for prototypes.
There is no Fortran header file since there are no functions.

The checksum of a contiguous block of data may be generated with 
\begin{verbatim}
      call checksum_simple(len, data, sum)
\end{verbatim}
--- to get more sophisticated see below and have a look at \verb+ftest.F+.

\begin{verbatim}
C:    void checksum_init(void);
F77:  subroutine checksum_init()
\end{verbatim}

  Initialize the internal checksum.  \verb+checksum_update()+ may then
  be called repeatedly.  The result does NOT depend on the number
  of calls to \verb+checksum_update()+ - e.g., the checksum of an array
  element-by-element is the same as the checksum of all elements 
  (in the same order) at once.

\begin{verbatim}
C:    void checksum_update(int len, const void *buf)
F77:  subroutine checksum_update(len, buf)
      integer len                      ! [input] length in bytes
      <anything but character> buf(*)  ! [input] data to sum
\end{verbatim}

  Update the internal checksum with len bytes of data from the 
  location pointed to by buf.  Fortran may use the MA routines
  for portable conversion of lengths into bytes.

\begin{verbatim}
F77:  subroutine checksum_char_update(buf)
      character*(*) buf                ! [input] data to sum
\end{verbatim}

  Same as \verb+checksum_update()+ but only for Fortran character strings
  (trailing blanks are included).

\begin{verbatim}
C:    void checksum_final(char sum[33])
F77:  subroutine checksum_final(sum)
      character*32 sum                 ! [output] checksum
\end{verbatim}

  Finish generating the checksum and return the checksum value
  as a C (null terminated) or Fortran character string.

\begin{verbatim}
C:    void checksum_simple(int len, const void *buf, char sum[33]);
F77:  subroutine checksum_simple(len, buf, sum)
      integer len                      ! [input] length in bytes
      <anything but character> buf(*)  ! [input] data to sum
      character*32 sum                 ! [output] checksum
\end{verbatim}

  Convenience routine when checksumming a single piece of data.
  Same as:
\begin{verbatim}
            call checksum_init()
            call checksum_update(len, buf)
            call checksum_final(sum)
\end{verbatim}

\begin{verbatim}
F77:  subroutine checksum_char_simple(buf, sum)
      character*(*) buf                ! [input] data to sum
      character*32 sum                 ! [output] checksum
\end{verbatim}

  Same as \verb+checksum_simple()+ but only for Fortran character strings
  (trailing blanks are included).


\subsection{Source version information}

\subsubsection{{\tt util\_version}}
\begin{verbatim}
  subroutine util_version
\end{verbatim}
By default this routine does nothing since it is expensive to
construct.  If you execute the command {\tt make version} in the
{\tt util} directory then all configured source files will be
processed to generate a copy \verb+util_version+ which when called
will printout the name and version information of all source files,
organized by module.  Of course, you'll also have to relink.

\subsection{Times and dates}

\subsubsection{{\tt util\_cpusec}}
\begin{verbatim}
  double precision function util_cpusec()
\end{verbatim}
This function returns the cputime in seconds from the start of the
process.  On some systems this number will be the same as the wall
time. The resolution and call overhead will also vary.  This routine
should provide the most accurate cputime.  On nearly all systems the
clocks are not synchronized between processes.

\subsubsection{{\tt util\_wallsec}}
\begin{verbatim}
      double precision function util_wallsec()
\end{verbatim}
Routine to return wall clock seconds since the start of execution.  On
nearly all systems the clocks are not synchronized between processes.
Resolution will also vary.

\subsubsection{{\tt util\_date}}
\begin{verbatim}
  subroutine util_date(date)
  character*(*) date         [output]
\end{verbatim}
Routine to return to Fortran the current date in the same format as the
standard C routine {\tt ctime()}.  Note that there are 26 characters
in this format and a fatal error will result if the argument {\tt
  date} is too small.

\subsection{System operations and information}

\subsubsection{{\tt util\_hostname}}
\begin{verbatim}
  subroutine util_hostname(name)
  character*(*) name         [output]
\end{verbatim}
Returns in {\tt name} the hostname of the machine.  A fatal error
results if {\tt name} is too small to hold the result --- 256
characters should suffice.

\subsubsection{{\tt util\_file\_unlink}}
\begin{verbatim}
  subroutine util_file_unlink(filename)
  character*(*) filename      [input]
\end{verbatim}
The calling process executes the \verb+unlink()+ system call to delete
the file.  If the file does not exist then it quietly returns.  If the
file exists and the unlink fails then it aborts calling
\verb+ga_error()+.

\subsubsection{{\tt util\_file\_copy}}
\begin{verbatim}
  subroutine util_file_copy(input, output)
  character*(*) input        [input]
  character*(*) output       [input]
\end{verbatim}
The calling process copies the named input file to the named output
file.  All errors are fatal.

\subsubsection{{\tt util\_system}}
\begin{verbatim}
  integer function util_system(command)
  character*(*) command      [input]
\end{verbatim}
The calling processes executes the UNIX system call \verb+system()+
with \verb+command+ as an argument.  This executes \verb+command+
inside the Bourne shell.  Returned is the completion code of the
command (typically 0 on success). If this functionality is not
supported on a given machine then a non-zero value (1) is returned.

\subsection{C to Fortran interface}

\subsubsection{{\tt string\_to\_fortchar} and {\tt
    fortchar\_to\_string}}
\begin{verbatim}
#ifdef CRAY
#include "fortran.h"
int string_to_fortchar(_fcd f, int flen, char *buf);
int fortchar_to_string(_fcd f, int flen, char *buf, 
                       const int buflen);
#else
int string_to_fortchar(char *f, int flen, char *buf);
int fortchar_to_string(const char *f, int flen, char *buf, 
                       const int buflen);
#endif
\end{verbatim}
These C callable routines automate the tricky conversion of C
null-terminated character strings to Fortran character strings
(\verb+string_to_fortchar+) and vice versa
(\verb+fortchar_to_string+).  The Cray interface is 
complicated by their use of character descriptors. We describe the
non-Cray interface.
\begin{itemize}
\item {\tt f} --- a pointer to the Fortran character string
\item {\tt flen} --- the length of the Fortran string (i.e., number of
  storage locations in bytes)
\item {\tt buf} --- pointer to the C character string
\item {\tt buflen} --- the size of buf (i.e., number of bytes in the
  buffer).
\end{itemize}
In converting to C format, strings are stripped of trailing blanks and
terminated with a null-character. In converting to Fortran format, the
null character is removed and the Fortran string padded on the right
with blanks.


\subsection{Debugging aids}

\subsubsection{{\tt ieeetrap}}

\subsection{Miscellaneous BLAS-like operations}

dabsmax.F --- to be removed

dabssum.F --- to be removed

rsg.f --- Eispack diagonalization routine --- should use Lapack
equivalent instead


\subsubsection{Initializing arrays --- {\tt dfill} and {\tt ifill}}

\begin{verbatim}
  subroutine dfill(n, s, x, ix)
  integer n             ! [input]  No. of elements to initialize
  double precision s    ! [input]  Value to set each element to
  double precision x(*) ! [output] Array to initialize
  integer ix            ! [input]  Stride between elements

  subroutine ifill(n, i, m, im)
  integer n             ! [input]  No. of elements to initialize
  integer i             ! [input]  Value to set each element to
  integer m(*)          ! [output] Array to initialize
  integer im            ! [input]  Stride between elements
\end{verbatim}

Initialize \verb+n+ elements of the array \verb+x(*)+ to the value
\verb+s+.  The stride between elements is specified by \verb+ix+ which
should be specified as one for contiguous data.  Routine
\verb+ifill()+ should be used for integer data.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Operations on Global Arrays}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Most of these routines are in the utility directory, but are
documented here for better organization.  These routines all operate
with global arrays and are (spuriously?)  prefaced with \verb+ga_+ but
are not part of the GA library.  Some reference other NWChem objects,
such as geometries or basis sets.

All of these routines are collective --- i.e., all processes must
invoke them at the same time, otherwise deadlock or a fatal error will
result.

\subsection{Simple linear operations}

\subsubsection{{\tt ga\_get\_diag}}
\begin{verbatim}
  subroutine ga_get_diagonal(g_a, diags)
  integer g_a               ! [input] GA handle
  double precision diags(*) ! [output] diagonals
\end{verbatim}
Extracts the diagonal elements of the square (real) global array in a
'scalable' fashion, broadcasting the result to everyone.  The local
array (\verb+diags+) must be large enough to hold the result.  The
only communication is (apart from synchronization to avoid a race
condition) is a global sum of length the diagonal.

\subsubsection{{\tt ga\_maxelt}}
\begin{verbatim}
   subroutine ga_maxelt(g_a, value)
   integer g_a            ! [input] GA handle
   double precision value ! [output] abs max value
\end{verbatim}
Returns the absolute value of the element with largest absolute
magnitude.  The only communication is (apart from synchronization to
avoid a race condition) is a global maximum of unit length.

\subsubsection{{\tt ga\_ran\_fill}}
\begin{verbatim}
  subroutine ga_ran_fill(g_a, ilo, ihi, jlo, jhi)
  integer g_a                ! [input] GA handle
  integer ilo, ihi, jlo, jhi ! [input] patch specification
\end{verbatim}
Fills a patch of a global array (\verb+a(ilo:ihi,jlo:jhi)+) with
random numbers uniformly distributed between 0 and 1.  The only
communication is necessary synchronization.

\subsubsection{{\tt ga\_screen}}
\begin{verbatim}
   subroutine ga_screen(g_a, value)
   integer g_a            ! [input] GA handle
   double precision value ! [input] Threshold
\end{verbatim}
Set all elements whose absolute value is less than {\tt value} to a
hard zero.  The only communication is necessary synchronization.

\subsubsection{{\tt ga\_mat2col} and {\tt ga\_col2mat}}
\begin{verbatim}
  subroutine ga_mat2col( g_a, ailo, aihi, ajlo, ajhi,
 &   g_b, bilo, bihi, bjlo, bjhi)
  integer g_a
  integer g_b
  integer ailo, aihi, ajlo, ajhi
  integer bilo, bihi, bjlo, bjhi

  subroutine ga_col2mat( g_a, ailo, aihi, ajlo, ajhi,
 &   g_b, bilo, bihi, bjlo, bjhi)
  integer g_a
  integer g_b
  integer ailo, aihi, ajlo, ajhi
  integer bilo, bihi, bjlo, bjhi
\end{verbatim}
Obsolete routines to copy patches with reshaping. Use \verb+ga_copy_patch+
instead.

\subsection{Linear algebra and transformations}

\subsubsection{{\tt ga\_mix}}
\begin{verbatim}
  subroutine ga_mix(g_a, n, nvec, b, ld)
  integer g_a                 [input]
  integer n, nvec, ld         [input]
  double precision b(ld,nvec) [input]
\end{verbatim}
This routine is set up to optimize the rotation of a (small) set of
vectors amoung themselves.  The matrix ($A(n,n_{vec})$) referenced by
GA handle \verb+g_a+ must be distributed by columns so that an entire
row is present on a processor --- a fatal error results if this is not
the case.  The matrix {\tt b} must be replicated.  With these
conditions no communication is necessary, other than that required for
synchronizations to avoid race conditions.  The routine performs the
following operation
\begin{displaymath}
     A_{ij} \Leftarrow \sum_{l=1,n_{vec}} A_{il} B_{lj}, i=1,n; j=1,n_{vec}
\end{displaymath}
which can be regarded as a multiplication of two matrices, one global
and the other local, with the result overwriting the input global
matrix.

It would be easy to make this routine use more general distributions
but still leave the optimized code for columnwise distribution.

\subsubsection{{\tt two\_index\_transf}}
\begin{verbatim}
  subroutine two_index_transf( g_a, g_lhs, g_rhs, g_tmp, g_b )
  integer g_a           ! [input] Handle to initial GA
  integer g_lhs, g_rhs  ! [input] Handles to transformation
  integer g_tmp         ! [input] Handle to scratch GA
  integer g_b           ! [input] Handle to output GA
\end{verbatim}
Two-index square matrix transform --- $B = U_{LHS}^T A U_{RHS}$.  Done
using calls to \verb+ga_dgemm+.  The scratch array must be a square
array of the same dimension as all the other arrays.  It would be easy
(and very useful) to generalize this to handle non-square transformations.

\subsubsection{{\tt ga\_matpow}}
\begin{verbatim}
  subroutine ga_matpow(g_v, pow, mineval)
  integer g_v              ! [input/output] Handle to GA
  double precision pow     ! [input] Exponent
  double precision mineval ! [input] Threshold for evals
\end{verbatim}
The square matrix referenced by \verb+g_v+ is raised to the power
\verb+pow+ by diagonalizing it, discarding (if \verb+pow+ is les than
zero) eigenvectors whose eigenvalue is smaller than \verb+mineval+,
raising the diagonal matrix to the required power, and transforming
back.  The only allowed values for \verb+pow+ are 1, -1,
$\frac{1}{2}$, and $\frac{-1}{2}$, though it would be easy to
generalize the routine to handle any value.

The input GA is overwritten with the exponentiated result.  It is {\em
not} guaranteed that the same handle will be returned -- if it is most
efficient, the original GA may be destroyed and a new GA created to
hold the result.

Uses a GA the size of V, and a local array the size of the number
of rows of V.  The eigensolver requires additional memory.

Due to the use of a generalized eigensolver, an additional GA the size
of V is also used.

\subsubsection{{\tt mk\_fit\_xf}}
\begin{verbatim}
  logical function mk_fit_xf(approx, split, basis, mineval, g_v)
  character*(*) approx, split [input]
  integer basis               [input]
  integer g_v                 [output]
  double precision mineval    [input]
\end{verbatim}
Returns in \verb+g_v+ a newly allocated global array containing the
appropriate fitting matrix for the specified
resolution-of-the-identity (RI) approximation.

 Arguments:
\begin{itemize}
\item \verb+approx+ --- RI approximation used (SVS, S, or V)
\item \verb+split+ ---  Whether or not to return the square root of the matrix
              so that it can be used to transform both sets of 3c ints.
              (Y or N).
\item \verb+basis+ --- Handle to fitting basis
\item \verb+mineval+ --- Minimum eigenvalue of V matrix to be retained in 
              the inversion
\item \verb+g_v+ ---  Returns new global array handle to the $V^{-1/2}$ matrix
\end{itemize}

Return value:
\begin{itemize}
\item \TRUE\ if successful, even if some eigenvalues fell below \verb+mineval+.
\item \FALSE\ if errors occured in dynamic memory (MA or GA) operations,
inquiries about the basis, or in obtaining the required integrals.

Note: the integral package must be initialized before calling this routine.

Memory use:
\item Creates and returns a global array (\verb+g_v+) the size of 
\verb+bas_numbf(basis)+$^2$.
\item Additional temporary usage consists of the largest of:
\begin{enumerate}
\item Integral requirements, reported by \verb+int_mem_2e2c+.
\item \verb+bas_numbf(basis)+$^2$ + \verb+bas_numbf(basis)+ and whatever additional
        space is required by \verb+ga_diag_std+.
\item 2 * \verb+bas_numbf(basis)+$^2$.
\end{enumerate}
\end{itemize}

\subsubsection{{ga\_orthog}}
\begin{verbatim}
  subroutine ga_orthog(g_vecs, g_over, ometric)
  integer g_vecs  ! [input] Vectors to be orthonormalized
  integer g_over  ! [input] Optional metric/overlap matrix
  logical ometric ! [input] If .true. use metric matrix
\end{verbatim}
The columns of the GA referenced by the handle \verb+g_vecs+ are
assumed to be vectors that must be orthonormalized.  If \verb+ometric+
is specified as \FALSE\ then the standard inner product is used.
Otherwise the \verb+g_over+ is assumed to refer to the metric (or
overlap).  Internally, MA is used to allocate a copy of the matrix
(and the metric) in a specific distribution.  If insufficient memory
is available or the matrix is singular a fatal error results.

\subsubsection{{\tt ga\_orthog\_vec}}
\begin{verbatim}
  subroutine ga_orthog_vec(n, nvec, g_m, g_x, j) 
  integer n    ! vector length 
  integer nvec ! no. of vectors 
  integer g_m  ! GA handle for matrix 
  integer g_x  ! GA handle for vector 
  integer j    ! Column for vector
\end{verbatim}
Orthogonalize the vector \verb+x(1:n,j)+ to the vectors
\verb+g(1:n,1:nvec)+.  Note that x is {\em not} normalized.  This routine
is/was used by some of the iterative equation solvers.

\subsection{Iterative linear algebra operations}

\subsubsection{{\tt ga\_iter\_diag}}
\begin{verbatim}
  logical function ga_iter_diag(n, nroot, maxiter, maxsub, tol,
 &     precond, product, oprint, eval0, g_evec, eval, rnorm, iter)
  integer n                 ! Matrix dimension
  integer nroot             ! No. of eigen vectors sought
  integer maxiter           ! Max. no. of iterations
  integer maxsub            ! Max. dimension of iterative subspace
  double precision tol      ! Required norm of residual
  external precond          ! Preconditioner
  external product          ! Matrix-vector product
  logical oprint            ! Control printing to unit 6
  double precision eval0    ! Estimate of lowest eval
  integer g_evec            ! n by nroot GA for guess and final
  double precision eval(nroot) ! Returns eigen values
  double precision rnorm(nroot) ! Returns residual norms
  integer iter              ! Returns no. of iterations used
\end{verbatim}
  Solve the eigenvalue equation ${\bf A}x = \lambda x$ with the
vectors $x$ in GA and a routine (product) to form a matrix vector
products to a required precision.  Return \TRUE\ if converged, \FALSE
otherwise. Rnorm returns the actual attained precision for each root.
     
The block-Davidson-like algorithm solves for the best solution for
each eigenvector in the iterative subspace ($x_i, i = 1, k$) with
\begin{displaymath}
  {\bf A} y = {\bf S}y\lambda, \mbox{where} A_{ij} = x_i^{\dagger} A x_j,
\mbox{and} S_{ij} = x_i^{\dagger} x_j
\end{displaymath}
 {\em NB:} The matrix vector products ${\bf A}x_i$ are performed by the user
provided routine \verb+product()+ to a precision specified by this routine
(currently products are performed one at a time, but it is easy to
improve the routine to perform many in one call).
     
The best solution within the iterative subspace is then
\begin{displaymath}
  x = \sum_i y_i x_i
\end{displaymath}
New expansion vectors are added by multiplying the residual
\begin{displaymath}
  r = ({\bf A} - s {\bf I}) x, \mbox{where} s \mbox{is the shift},
\end{displaymath}
with some approximation ($P$) to the inverse of ${\bf A}-s{\bf I}$.
This preconditioning is performed by the user provided routine
\verb+precond()+.  If \verb+eval0+ is a hard zero then the shift ($s$) is
chosen as the current estimate for the eigenvalue that the next update
strives to improve.  Otherwise the shift is fixed as \verb+eval0+
which is appropriate for convergence to a known energy spectrum from
some poor initial guess.
     
  The program cyles through the lowest nroot roots updating each that
does not yet satisfy the convergence criterion which is
\begin{displaymath}
   {\tt rnorm(root)} = ||r|| < {\tt tol}
\end{displaymath}

 On input the global array \verb+x(n,nroot)+ should contain either an
initial guess at the eigen vectors or zeroes.  If any vector is zero
then random numbers are used.

The use must proivde these routines:
\begin{itemize}
\item \verb+subroutine product(precision, g_x, g_ax)+ ---
     computes the product ${\bf A}x$ to the specified precision (absolute
     magnitude error in any element of the product) returning the result
     in the GA \verb+g_ax+.
\item \verb+subroutine precond(g_r, shift)+ ---
     Apply an approximation ($P$) to the inverse of ${\bf A} - s {\bf
     I}$ to the vector in \verb+g_r+ overwriting \verb+g_r+ with the result.
\end{itemize}
     
If the initial guess is zero no redundant matrix product is formed.
    
Temporary global arrays of dimension \verb+n*maxsub+, \verb+n*maxsub+, 
\verb+n+ and \verb+n+ are created.


\subsubsection{{\tt ga\_iter\_lsolve}}

\subsubsection{{\tt ga\_iter\_orthog}}

\subsubsection{{\tt ga\_iter\_project}}

\subsection{Miscellaneous}

\subsubsection{{\tt ga\_pcg\_minimize}}

\subsubsection{{\tt int\_1e\_ga}}

\subsubsection{{\tt int\_2c\_ga}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\include{integral_api} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Performance Statistics Collection --- PSTAT}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The pstat library is intended to facilitate collecting and reporting
performance statistics for parallel programs.  The design is based to
some extent on the ptimer and pmon facilities provided by Kendall
Square Research, and also by getstat in the COLUMBUS program system.

\subsection{Model}

Applications can allocate ``timers'' associated with events in the
program.  ``Timers'' are actually generalized data structures which
can record elapsed CPU and wall clock time, accumulate information
(i.e. the number of integrals produced) and other (possibly
system-dependent) data. (In the present implementation only times and
accumulators are available.)  Timers are represented within the
program by opaque handles.

\subsection{API}

\subsubsection{Include files}
All routines using the pstat library should include \verb+pstat.fh+,
which includes predefined constants for the various statistics that
can be collected.

\subsubsection{{\tt pstat\_init}}
\begin{verbatim}
Status = PStat_Init( Max_Timers, NAcc, Names )
Logical Status
Integer Max_Timers, NAcc [IN]
Character*(*) Names(NAcc) [IN]
\end{verbatim}
Initialize package, reserving space for Max\_Timers different
timers.  Also defines NAcc user-defined accumulation registers
labeled by the given Names.

\subsubsection{{\tt pstat\_terminate}}
\begin{verbatim}
Status = PStat_Terminate()
Logical Status
\end{verbatim}
Free up all temporary space used by pstat package

\subsubsection{{\tt pstat\_allocate}}
\begin{verbatim}
Status = PStat_Allocate( Name, Functions, NAcc, Accumulators, Handle )
Logical Status [OUT]
Character*(*) Name [IN]
Integer Functions [IN], NAcc [IN], Accumulators(NAcc) [IN], Handle [OUT]
\end{verbatim}
Create a timer with the given descriptive name which records
the statistics described by the Functions argument. This timer
will also allow accumulation into the NAcc accumulation
registers listed in the Accumulators array.

\subsubsection{{\tt pstat\_free}}
\begin{verbatim}
Status = PStat_Free( Handle )
Logical Status [OUT]
Integer Handle [IN]
\end{verbatim}
Frees up a timer so it can be re-pstat\_allocated later.  Does
not free the storage associated with the timer.

\subsubsection{{\tt pstat\_on}}
\begin{verbatim}
PStat_On( Handle )
Integer Handle [IN]
\end{verbatim}
Start statistics gathering for the timer Handle.  Routine
aborts with an error if timer is not in the "off" state at
invocation.  Aborts with an error if Handle is not assigned.

\subsubsection{{\tt pstat\_off}}
\begin{verbatim}
PStat_Off( Handle )
Integer Handle [IN]
\end{verbatim}
End statistics gathering for the timer Handle.  Routine aborts
with an error if timer is not in the "on" state at invocation.
Aborts with an error if Handle is not assigned.

\subsubsection{{\tt pstat\_acc}}
\begin{verbatim}
PStat_Acc( Handle, N, Data)
Integer Handle, N [IN]
Double precision Data(N) [IN]
\end{verbatim}
Accumulate Data into the registers defined when Handle was
allocated. N must match the number of accumulation registers
specified in the declaration of the timer, and the elements of
Data will be added to the registers as specified in the
Accumulators array used then the timer was allocated.

\subsubsection{{\tt pstat\_print\_all} and {\tt pstat\_print}}
\begin{verbatim}
PStat_Print_All
PStat_Print( Functions, NAcc, Accumulators )
Integer Functions, NAcc, Accumulators(NAcc) [IN]
\end{verbatim}
Write a summary of statistics to stdout.  PStat\_Print\_All
reports all data which has been collected.  PStat\_Print
reports those data specified in Functions and Accumulators.
The report includes the number of calls to each timer and the
data specified by Functions.  For all data, including the
number of calls, the min, max, and average across all
processes is reported.
        
\subsubsection{Usage Notes}
In normal usage, an application module would allocate the appropriate
timers, normally in a subroutine, and store the handles in a common
block which is included by all routines in the module which use
PStat.  This is separate from the \verb+pstat.fh+ include file.
And of course another subroutine at the end of the module would
normally be used to free the timers.

The core routines, PStat\_\{On,Off,Acc\}, do not return error codes in
order to simplify putting them into \& removing them from code easily.
They abort with an error if the timer handle is invalid, or if they
are called out of sequence (PStat\_On and PStat\_Off must be paired).

Different machines have different capabilities w.r.t. performance
statistics collection.  Those functions which are not available on a
given implementation will be silently ignored.  

In order to minimize the overhead of checking which statistics to
collect in each PStat\_\{On,Off\} call, the functions should represent
related groups of statistics rather than a single item.  Three
predefined groups will always be available: PStat\_NoStats, which is a
NOP (for example when a timer will use only user-defined
accumulators), PStat\_AllStats, which expands to all available
functions, and PStat\_QStat, which is a minimal (quick) set (CPU time
and wall clock time) intended for low-overhead usage.  Multiple
functions can be requested by adding their values together with the
exception of PStat\_QStat (to keep overhead low, PStat\_QStat is checked
first, and if true, no other functions are checked.

\subsection{Closing Comment}
The current version of pstat was created as a throwaway prototype, but
it hasn't been thrown away quite yet.  Things can certainly be
improved, and hopefully they will be in due course.  One of the most
important design flaws is the lack of context-dependence in the
timers. As an excuse, I can only offer that we {\em still} don't have
a grip on how to handle context in general, so it is not surprising
that pstat doesn't have it.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Integral File I/O -- INT2E}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Application- and I/O-Level Views of the Data Stream}

The data stream coming into the package from the application consists
of (floating point) integral values and (integer) labels (four labels
per value) interspersed with calls which specify the ranges of the
four labels for subsequent integrals.

On disk (or in the package's cache) the data appears in compressed
form, in chunks of 64 KB holding up to 8192 value/label sets, some of
which may contain structural information rather than integral data.

\subsection{Internal Data Structures (all are node-private)}

\begin{verbatim}
buffer (common block /cint2efile/)
        integer                 n_per_rec = 8192
        double precision        values(n_per_rec)
        integer                 labels(4, n_per_rec)
        integer                 n_in_rec
\end{verbatim}
VALUES are actual floating point integral values and must be bounded
in absolute value by MAXVALUE to allow for the fixed-point compression
scheme.

LABELS are basis function labels relative to RANGE (set by
int2e\_set\_bf\_range).  Must be representable in 8 bits to allow for
compression.

Some elements of the buffer are devoted to special purposes, in which
case the labels are used to store > 8 bit integer values and the
corresponding VALUES are set to zero (used in sanity checking).
Special purposes are (1) a counter of the number of values in the
current range (see int2e\_buf\_cntr\_\{pack,unpack\}), and (2) specifying a
new basis function range (see int2e\_set\_bf\_range).  The first element
of the buffer is always a counter.

Related values:
\begin{description}
\item[next\_value]       Points to next buffer element to be read/inserted
\item[cntr\_ptr]         Points to buffer element holding the current
                        integral counter
\item[nleft\_in\_range]   Running count of number of valid integrals
                        remaining in the range.  Initialized by
                        int2e\_buf\_cntr\_unpack and updated as the user
                        obtains integrals with int2e\_file\_read.
\end{description}

\begin{verbatim}
compressed buffer (common block /cint2ebuf/)
        integer                 n\_per\_rec = 8192
        double precision        buf(n\_per\_rec)
        integer                 n\_in\_buf, pad
\end{verbatim}

Note: BUF is equivalanced to the integer array IBUF.  The IBUF
representation is used during compression, while the BUF
representation is used for storage.  PAD insures that the common block
has an even length in doubles regardless of the relative size of
integers and doubles.

The first half of BUF contains the 32-bit integer fixed-point
representation of the VALUES array.  If the machine has 64-bit
integers, the fixed-point data are packed two per integer.  The final
half of BUF contains the LABELS array compressed to 8 bits per
element. (Note that the same bitstream results regardless of whether
the platform uses one or two integers per double. In the case of one
integer per double, the 32-bit fixed-point integral values are packed
two to a word.)

\subsubsection{Cache}

Each node allocates local memory to act as a cache for its file.  The
size of the cache is determined by user input (via the RTDB).
Operation is simple:  the cache is filled with the initial records of
integral data, the remainder go to disk.  Data is never moved between
cache and disk.

\subsection{Subprograms}

\subsubsection{{\tt sread, swrite} (in util directory)}


Read (write) an array of doubles on a Fortran sequential access file.
If more than 32767 elements (hardwired in the routines) are to be read
(written), it broken into multiple records of at most 32767 elements
each.

\subsubsection{{\tt int2e\_file\_open} (API)}


Initializes integral file management variables (including filename).
Determined numerical precision required to store (floating point)
integral values and produces a scaling factor for the fixed-point
compression scheme (values are represented as 32 bit integers relative
to this scale factor).  Allocates local memory for cache.  Does not
actually open the file (the Paragon is notorious for dying if you try
to open too many files simultaneously, so actual opening is deferred
until the first need to write, which is less likely to be
synchronous).

\subsubsection{{\tt int2e\_file\_close} (API)}

Closes integral files, frees cache (local memory).

\subsubsection{{\tt int2e\_file\_rewind} (API)}

Rewinds the integral files, clears buffer.

\subsubsection{{\tt int2e\_file\_read} (API)}

Fills user-provided arrays with integrals and four labels.  Operates
by repeated calls to int2e\_buf\_read followed by unpacking of the data
into the user-supplied arrays.  Unpacking involves adjusting the
labels to reflect the range as set by int2e\_set\_bf\_range.  Data is
read until MAXINTS (user-specified) values have been read or the end
of the current range (see int2e\_set\_bf\_range) is reached.  Returning
.FALSE. is a signal to call int2e\_get\_bf\_range before the next call to
this routine.

\subsubsection{{\tt int2e\_file\_write} (API)}

Copies data into internal buffers (currently 8192 elements, defined in
cint2efile.fh), writing to disk as the buffer fills.  As each integral
is being copied into the internal buffers, it is compared against a
value which is the limit of what can be represented in the fixed-point
compression scheme with the necessary precision.  If the integral
value exceeds this value (in absolute value) int2e\_file\_write\_big is
called deposit it into the buffer.


\subsubsection{{\tt int2e\_file\_write\_big} (internal)}

Splits up an integral too large to be represented accurately in the
fixed point compression scheme into multiple smaller integrals (same
labels, of course).

\subsubsection{{\tt int2e\_buf\_read, int2e\_buf\_write} (mostly internal)}

There is one application-level call to int2e\_buf\_write in
the SCF to insure that the final buffer is written to disk.

int2e\_buf\_read obtains a record of data from the cache (for records <
max\_cache\_rec) or from disk (via sread). The data is unpacked by
int2e\_buf\_unpack, and the number of integrals in the current range is
extracted. To write the buffer, the procedure is exactly the reverse.

\subsubsection{{\tt int2e\_buf\_clear} (internal)}

Resets buffer pointers to "zero", effectively emptying the buffer and
reserving the first entry in the buffer as a counter of the number of
data values in the record (or until int2e\_set\_bf\_range is called).

\subsubsection{{\tt int2e\_buf\_cntr\_pack, int2e\_buf\_cntr\_unpack} (internal)}

Prepares the number of integrals counter for the data compression
associated with storage.  The counter occupies the cntr\_ptr element in
the buffer.  During normal operation, the counter is maintained as an
integer in labels(1, cntr\_ptr), with no data in labels(2:4, cntr\_ptr)
or values(cntr\_ptr).  The counter can therefore represent up to
$2^{24}$. Since the data compression algorithm stores the label values as
8 bits each, the counter is "packed" (unpacked) by splitting it into
three bytes and stored in labels(1:3, cntr\_ptr).  Zeros are stored in
labels(4, cntr\_ptr) and values(cntr\_ptr) and used by int2e\_buf\_unpack
as as part of a sanity check.

The first element of each record is a counter, and additional counters
are generated by calls to int2e\_set\_bf\_range.

\subsubsection{{\tt int2e\_buf\_pack, int2e\_buf\_unpack} (internal)}

Compresses (decompresses) the integral buffer.  Integral values are
scaled to produce a 32 bit integer representation (fixed-point
compression).  Integral labels are packed into 32 bits as well.  On
machines with 64 bit integers, the compressed integrals and labels are
combined into a single datum.

\subsubsection{{\tt int2e\_set\_bf\_range, int2e\_get\_bf\_range} (API)}

Tells (extracts) the integral file module the ranges of the four
integral labels to follow. The specified range is effective until
it2e\_set\_bf\_range is called again to change it.

The lowest 16 bits of the eight limit values are stored in four
elements of the buffer as follows to survive the subsequent 8 bit
packing:
\begin{verbatim}
        high 8 bits: ilo, jlo, klo, llo --> labels(1:4, next_value    ) 
        high 8 bits: ihi, jhi, khi, lhi --> labels(1:4, next_value + 1) 
        low  8 bits: ilo, jlo, klo, llo --> labels(1:4, next_value + 3) 
        low  8 bits: ihi, jhi, khi, lhi --> labels(1:4, next_value + 4) 
\end{verbatim}
Calling int2e\_set\_bf\_range also terminates the current counter (see
int2e\_buf\_cntr\_\{pack,unpack\}) and starts a new one for the new basis
function range at next\_value+5.



\end{document}
